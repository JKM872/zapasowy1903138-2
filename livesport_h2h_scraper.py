"""
Livesport H2H scraper - Multi-Sport Edition
-------------------------------------------
Cel: dla danego dnia zapisaÄ‡ do pliku CSV wydarzenia (mecze), w ktÃ³rych GOSPODARZE pokonali przeciwnikÃ³w co najmniej 2 razy w ostatnich 5 bezpoÅ›rednich spotkaniach (H2H).

Wspierane sporty:
- PiÅ‚ka noÅ¼na (football/soccer)
- KoszykÃ³wka (basketball)
- SiatkÃ³wka (volleyball)
- PiÅ‚ka rÄ™czna (handball)
- Rugby
- Hokej (hockey/ice-hockey)

Uwagi / zaÅ‚oÅ¼enia:
- ZakÅ‚adam, Å¼e "ostatnie 5" oznacza 5 ostatnich bezpoÅ›rednich spotkaÅ„ miÄ™dzy obiema druÅ¼ynami (H2H na stronie meczu).
- Skrypt pracuje w trzech trybach:
    * --urls  : przetwarza listÄ™ adresÃ³w URL meczÃ³w (plik tekstowy z jednÄ… liniÄ… = jeden URL)
    * --auto  : prÃ³buje zebraÄ‡ listÄ™ linkÃ³w do meczÃ³w z ogÃ³lnej strony dla danego dnia
    * --sport : automatycznie zbiera linki dla konkretnych sportÃ³w
- Strona Livesport jest mocno zaleÅ¼na od JS â€” skrypt uÅ¼ywa Selenium (Chrome/Chromedriver).
- Przestrzegaj robots.txt i Terms of Use. Skrypt ma opÃ³Åºnienia (sleep) i limit prÃ³b, ale uÅ¼ywanie go na duÅ¼ej skali wymaga uzyskania zgody od wÅ‚aÅ›ciciela serwisu.

Wymagania:
- Python 3.9+
- pip install selenium beautifulsoup4 pandas webdriver-manager
- Chrome i dopasowany chromedriver (webdriver-manager uÅ‚atwia instalacjÄ™)

Uruchomienie (przykÅ‚ady):
python livesport_h2h_scraper.py --mode urls --date 2025-10-05 --input match_urls.txt --headless
python livesport_h2h_scraper.py --mode auto --date 2025-10-05 --sports football basketball --headless
python livesport_h2h_scraper.py --mode auto --date 2025-10-05 --sports football --leagues ekstraklasa premier-league --headless

Plik wynikowy: outputs/livesport_h2h_YYYY-MM-DD.csv (lub z sufixem sportu)

"""

import argparse
import time
import os
import sys
import csv
import re
import json
from datetime import datetime
from typing import List, Dict, Optional

# Fix Unicode encoding issues on Windows
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')

import pandas as pd
from bs4 import BeautifulSoup

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.common.exceptions import NoSuchElementException, TimeoutException, WebDriverException
from webdriver_manager.chrome import ChromeDriverManager

# Forebet integration
try:
    from forebet_scraper import search_forebet_prediction, format_forebet_result, prefetch_forebet_html
    FOREBET_AVAILABLE = True
except ImportError:
    FOREBET_AVAILABLE = False
    print("âš ï¸ forebet_scraper not available - predictions will be skipped")

# Gemini AI integration - LAZY LOADING to avoid blocking startup
GEMINI_AVAILABLE = None  # Will be checked on first use
gemini_analyze_match = None

def lazy_load_gemini():
    """Lazy load Gemini AI only when actually needed"""
    global GEMINI_AVAILABLE, gemini_analyze_match
    
    if GEMINI_AVAILABLE is None:  # First time check
        try:
            print("ðŸ¤– ÅadujÄ™ Gemini AI...")
            from gemini_analyzer import analyze_match as _gemini_analyze_match
            gemini_analyze_match = _gemini_analyze_match
            GEMINI_AVAILABLE = True
            print("âœ… Gemini AI gotowe!")
            return True
        except Exception as e:
            GEMINI_AVAILABLE = False
            print(f"âš ï¸ Gemini AI niedostÄ™pne: {type(e).__name__}")
            return False
    
    return GEMINI_AVAILABLE

# Nordic Bet integration (disabled - using FlashScore instead)
NORDIC_BET_AVAILABLE = False

# FlashScore odds integration
try:
    from flashscore_odds_scraper import FlashScoreOddsScraper, format_odds_for_display
    FLASHSCORE_AVAILABLE = True
    print("âœ… FlashScore odds scraper loaded")
except ImportError:
    FLASHSCORE_AVAILABLE = False
    print("âš ï¸ flashscore_odds_scraper not available - odds will use Forebet fallback")


# ----------------------
# Helper / scraper code
# ----------------------

def detect_sport_from_url(url):
    """
    Wykryj sport z URL LiveSport i zmapuj na nazwÄ™ sportu Forebet
    
    Mapowanie LiveSport -> Forebet:
    - pilka-nozna -> football/soccer
    - koszykowka -> basketball
    - siatkowka -> volleyball
    - pilka-reczna -> handball
    - rugby -> rugby
    - hokej -> hockey
    - tenis -> tennis
    """
    url_lower = url.lower()
    
    if '/pilka-nozna/' in url_lower or '/football/' in url_lower or '/soccer/' in url_lower:
        return 'football'
    elif '/koszykowka/' in url_lower or '/basketball/' in url_lower:
        return 'basketball'
    elif '/siatkowka/' in url_lower or '/volleyball/' in url_lower:
        return 'volleyball'
    elif '/pilka-reczna/' in url_lower or '/handball/' in url_lower:
        return 'handball'
    elif '/rugby/' in url_lower:
        return 'rugby'
    elif '/hokej/' in url_lower or '/hockey/' in url_lower or '/ice-hockey/' in url_lower:
        return 'hockey'
    elif '/tenis/' in url_lower or '/tennis/' in url_lower:
        return 'tennis'
    else:
        return 'football'  # domyÅ›lnie football

# Mapowanie sportÃ³w na URLe Livesport
SPORT_URLS = {
    'football': 'https://www.livesport.com/pl/pilka-nozna/',
    'soccer': 'https://www.livesport.com/pl/pilka-nozna/',
    'basketball': 'https://www.livesport.com/pl/koszykowka/',
    'volleyball': 'https://www.livesport.com/pl/siatkowka/',
    'handball': 'https://www.livesport.com/pl/pilka-reczna/',
    'rugby': 'https://www.livesport.com/pl/rugby/',
    'hockey': 'https://www.livesport.com/pl/hokej/',
    'ice-hockey': 'https://www.livesport.com/pl/hokej/',
    'tennis': 'https://www.livesport.com/pl/tenis/',
}

# Sporty indywidualne (inna logika kwalifikacji)
INDIVIDUAL_SPORTS = ['tennis']

# Popularne ligi dla kaÅ¼dego sportu (mapowanie slug -> nazwa)
POPULAR_LEAGUES = {
    'football': {
        'ekstraklasa': 'Ekstraklasa',
        'premier-league': 'Premier League',
        'la-liga': 'LaLiga',
        'bundesliga': 'Bundesliga',
        'serie-a': 'Serie A',
        'ligue-1': 'Ligue 1',
        'champions-league': 'Liga MistrzÃ³w',
        'europa-league': 'Liga Europy',
    },
    'basketball': {
        'nba': 'NBA',
        'euroleague': 'Euroliga',
        'energa-basket-liga': 'Energa Basket Liga',
        'pbl': 'Polska Liga KoszykÃ³wki',
    },
    'volleyball': {
        'plusliga': 'PlusLiga',
        'tauron-liga': 'Tauron Liga',
    },
    'handball': {
        'pgnig-superliga': 'PGNiG Superliga',
    },
    'rugby': {
        'premiership': 'Premiership',
        'top-14': 'Top 14',
    },
    'hockey': {
        'nhl': 'NHL',
        'khl': 'KHL',
    },
}

H2H_TAB_TEXT_OPTIONS = ["H2H", "Head-to-Head", "BezpoÅ›rednie", "BezpoÅ›rednie spotkania", "H2H"]


def start_driver(headless: bool = True) -> webdriver.Chrome:
    chrome_options = Options()
    if headless:
        chrome_options.add_argument("--headless=new")
    
    # ðŸ”¥ QUADRUPLE FORCE: Aggressive stability settings
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument('--window-size=1920,1080')
    
    # Network stability improvements
    chrome_options.add_argument("--disable-web-security")
    chrome_options.add_argument("--disable-features=IsolateOrigins,site-per-process")
    chrome_options.add_argument("--disable-background-networking")
    chrome_options.add_argument("--dns-prefetch-disable")
    
    # Connection pool settings
    chrome_options.add_argument("--max-connections-per-host=6")
    
    # Timeout preferences
    chrome_options.add_experimental_option('prefs', {
        'profile.default_content_setting_values.notifications': 2,
        'profile.default_content_settings.popups': 0,
    })
    
    # human-like user-agent (you may rotate)
    chrome_options.add_argument(
        "--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    )

    # Try to find cached ChromeDriver first (manual or auto-downloaded)
    import glob
    print("ðŸ” Sprawdzam ChromeDriver...")
    
    cache_pattern = os.path.join(os.path.expanduser("~"), ".wdm", "drivers", "chromedriver", "**", "chromedriver.exe")
    cached_drivers = glob.glob(cache_pattern, recursive=True)
    
    if cached_drivers:
        # Sort by path to get the newest version (highest number)
        cached_drivers.sort(reverse=True)
        driver_path = cached_drivers[0]
        print(f"âœ… Znaleziono ChromeDriver w cache: {driver_path}")
        
        # ðŸ”¥ QUADRUPLE FORCE: Aggressive timeouts for Service
        service = Service(
            driver_path,
            log_path='NUL' if sys.platform == 'win32' else '/dev/null',  # Suppress logs
        )
        
        # Create driver with extended timeouts
        driver = webdriver.Chrome(service=service, options=chrome_options)
        
        # ðŸ”¥ QUADRUPLE FORCE: Set aggressive page load timeout
        driver.set_page_load_timeout(60)  # 60 seconds for page load
        driver.set_script_timeout(30)  # 30 seconds for scripts
        driver.implicitly_wait(10)  # 10 seconds implicit wait
    else:
        # Fall back to ChromeDriverManager
        print("âš ï¸ Pobieranie ChromeDriver przez ChromeDriverManager...")
        try:
            service = Service(
                ChromeDriverManager().install(),
                log_path='NUL' if sys.platform == 'win32' else '/dev/null',
            )
            driver = webdriver.Chrome(service=service, options=chrome_options)
            driver.set_page_load_timeout(60)
            driver.set_script_timeout(30)
            driver.implicitly_wait(10)
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d podczas inicjalizacji ChromeDriver: {e}")
            print("ðŸ’¡ SprÃ³buj: pip install --upgrade selenium webdriver-manager")
            raise
    
    return driver


def click_h2h_tab(driver: webdriver.Chrome) -> None:
    """SprÃ³buj kliknÄ…Ä‡ zakÅ‚adkÄ™ H2H - sprawdzamy kilka wariantÃ³w tekstowych i atrybutÃ³w."""
    for text in H2H_TAB_TEXT_OPTIONS:
        try:
            # XPath contains text
            el = driver.find_element(By.XPATH, f"//a[contains(translate(normalize-space(.), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), '{text.lower()}')]")
            el.click()
            time.sleep(0.8)
            return
        except Exception:
            pass

    # fallback: look for element with data-tab or href containing 'h2h'
    try:
        el = driver.find_element(By.XPATH, "//a[contains(@href, 'h2h') or contains(@data-tab, 'h2h')]")
        el.click()
        time.sleep(0.8)
        return
    except Exception:
        pass

    # if nothing works, do nothing and hope content is already present


def parse_h2h_from_soup(soup: BeautifulSoup, home_team: str) -> List[Dict]:
    """Parsuje sekcjÄ™ H2H i zwraca listÄ™ ostatnich spotkaÅ„ (do 5).
    Zwracany format: [{'date':..., 'home':..., 'away':..., 'score': 'x - y', 'winner': 'home'/'away'/'draw'}]
    """
    results = []

    # NOWA STRUKTURA LIVESPORT (2025)
    # Szukaj sekcji "Pojedynki bezpoÅ›rednie"
    h2h_sections = soup.find_all('div', class_='h2h__section')
    
    pojedynki_section = None
    for section in h2h_sections:
        text = section.get_text(" ", strip=True)
        if 'pojedynki' in text.lower() or 'bezpoÅ›rednie' in text.lower():
            pojedynki_section = section
            break
    
    if not pojedynki_section:
        # Fallback: weÅº pierwszÄ… sekcjÄ™ h2h__section
        if h2h_sections:
            pojedynki_section = h2h_sections[0]
    
    if not pojedynki_section:
        return results
    
    # ZnajdÅº wiersze z meczami: a.h2h__row
    match_rows = pojedynki_section.select('a.h2h__row')
    
    for row in match_rows[:5]:  # Maksymalnie 5 ostatnich
        try:
            # Data
            date_el = row.select_one('span.h2h__date')
            date = date_el.get_text(strip=True) if date_el else ''
            
            # Gospodarz
            home_el = row.select_one('span.h2h__homeParticipant span.h2h__participantInner')
            home = home_el.get_text(strip=True) if home_el else ''
            
            # GoÅ›Ä‡
            away_el = row.select_one('span.h2h__awayParticipant span.h2h__participantInner')
            away = away_el.get_text(strip=True) if away_el else ''
            
            # Wynik
            score = ''
            winner = 'unknown'
            result_spans = row.select('span.h2h__result span')
            
            if len(result_spans) >= 2:
                goals_home = result_spans[0].get_text(strip=True)
                goals_away = result_spans[1].get_text(strip=True)
                score = f"{goals_home}-{goals_away}"
                
                # Determine winner
                try:
                    gh = int(goals_home)
                    ga = int(goals_away)
                    if gh > ga:
                        winner = 'home'
                    elif ga > gh:
                        winner = 'away'
                    else:
                        winner = 'draw'
                except:
                    winner = 'unknown'

            if home and away and score:
                results.append({
                    'date': date,
                    'home': home,
                    'away': away,
                    'score': score,
                    'winner': winner,
                    'raw': f"{date} {home} {score} {away}"
                })
        
        except Exception as e:
            continue

    return results


def process_match(url: str, driver: webdriver.Chrome, away_team_focus: bool = False, use_forebet: bool = False, use_gemini: bool = False, use_sofascore: bool = False, use_flashscore: bool = False, sport: str = 'football') -> Dict:
    """Odwiedza stronÄ™ meczu, otwiera H2H i zwraca informacjÄ™ we wÅ‚aÅ›ciwym formacie.
    
    Args:
        url: URL meczu
        driver: Selenium WebDriver
        away_team_focus: JeÅ›li True, liczy zwyciÄ™stwa GOÅšCI w H2H zamiast gospodarzy
        use_forebet: JeÅ›li True, pobiera predykcje z Forebet
        use_gemini: JeÅ›li True, uÅ¼ywa Gemini AI do analizy
        sport: Sport (football, volleyball, etc.)
    """
    out = {
        'match_url': url,
        'home_team': None,
        'away_team': None,
        'match_time': None,
        'h2h_last5': [],
        'last_h2h_date': None,  # NOWE: Data ostatniego meczu H2H
        'home_wins_in_h2h_last5': 0,
        'away_wins_in_h2h_last5': 0,  # NOWE: dla trybu away_team_focus
        'h2h_count': 0,
        'win_rate': 0.0,  # % wygranych gospodarzy/goÅ›ci w H2H (zaleÅ¼nie od trybu)
        'qualifies': False,
        'home_form': [],  # Forma gospodarzy: ['W', 'L', 'W', 'D', 'W']
        'away_form': [],  # Forma goÅ›ci: ['L', 'L', 'W', 'L', 'W']
        'home_odds': None,  # Kursy bukmacherskie (info dodatkowa)
        'away_odds': None,
        'focus_team': 'away' if away_team_focus else 'home',  # NOWE: ktÃ³ry tryb
        # FOREBET PREDICTIONS
        'forebet_prediction': None,  # '1', 'X', '2'
        'forebet_probability': None,  # float (%)
        'forebet_exact_score': None,  # '1-3'
        'forebet_over_under': None,  # 'Over 2.5' / 'Under 2.5'
        'forebet_btts': None,  # 'Yes' / 'No'
        'forebet_avg_goals': None,  # float
        # GEMINI AI PREDICTIONS
        'gemini_prediction': None,  # KrÃ³tka predykcja AI (1-2 zdania)
        'gemini_confidence': None,  # 0-100% pewnoÅ›ci
        'gemini_reasoning': None,  # SzczegÃ³Å‚owe uzasadnienie
        'gemini_recommendation': None,  # HIGH/MEDIUM/LOW/SKIP
    }

    # ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ QUADRUPLE FORCE: Ultra-aggressive retry logic with multiple strategies
    max_retries = 5  # Increased from 3
    retry_delay = 2.0  # Start faster
    last_error = None
    
    for attempt in range(max_retries):
        try:
            # ðŸ”¥ Strategy 1: Normal navigation
            if attempt == 0:
                driver.get(url)
                time.sleep(3.0)  # Longer initial wait
            
            # ðŸ”¥ Strategy 2: Refresh if first failed
            elif attempt == 1:
                print(f"   ðŸ”„ PrÃ³ba #2: Refresh...")
                driver.refresh()
                time.sleep(3.0)
            
            # ðŸ”¥ Strategy 3: Navigate to main page first, then match
            elif attempt == 2:
                print(f"   ðŸ”„ PrÃ³ba #3: Via main page...")
                driver.get("https://www.livesport.com/pl/")
                time.sleep(2.0)
                driver.get(url)
                time.sleep(3.0)
            
            # ðŸ”¥ Strategy 4: Clear cache and try
            elif attempt == 3:
                print(f"   ðŸ”„ PrÃ³ba #4: Clear cache...")
                driver.delete_all_cookies()
                time.sleep(1.0)
                driver.get(url)
                time.sleep(3.0)
            
            # ðŸ”¥ Strategy 5: Last resort - direct URL
            else:
                print(f"   ðŸ”„ PrÃ³ba #5: Direct URL (last resort)...")
                driver.get(url)
                time.sleep(5.0)  # Extra long wait
            
            # Teraz sprÃ³buj kliknÄ…Ä‡ zakÅ‚adkÄ™ H2H
            click_h2h_tab(driver)
            time.sleep(2.5)  # Czekaj na zaÅ‚adowanie H2H
            break  # Success - wyjdÅº z pÄ™tli
            
        except (WebDriverException, ConnectionResetError, ConnectionError, TimeoutError) as e:
            last_error = e
            if attempt < max_retries - 1:
                print(f"âš ï¸ BÅ‚Ä…d poÅ‚Ä…czenia (prÃ³ba {attempt + 1}/{max_retries}): {type(e).__name__}")
                print(f"   Czekam {retry_delay:.1f}s przed nastÄ™pnÄ… prÃ³bÄ…...")
                time.sleep(retry_delay)
                retry_delay *= 1.3  # Gentler exponential backoff
                continue
            else:
                print(f"âŒ BÅ‚Ä…d otwierania {url} po {max_retries} prÃ³bach")
                print(f"   Ostatni bÅ‚Ä…d: {type(last_error).__name__}: {str(last_error)[:100]}")
                return out

    # pobierz tytuÅ‚ strony jako fallback na nazwy druzyn
    try:
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        # sprÃ³buj wyciÄ…gnÄ…Ä‡ nazwy druÅ¼yn z nagÅ‚Ã³wka
        title = soup.title.string if soup.title else ''
        if title:
            # tytuÅ‚ czÄ™sto ma formÄ™ "Home - Away" lub "Home vs Away"
            import re
            m = re.split(r"\s[-â€“â€”|]\s|\svs\s|\sv\s", title)
            if len(m) >= 2:
                out['home_team'] = m[0].strip()
                out['away_team'] = m[1].strip()
    except Exception:
        pass

    # NIE MUSIMY KLIKAÄ† H2H - juÅ¼ jesteÅ›my na stronie /h2h/ogolem/

    soup = BeautifulSoup(driver.page_source, 'html.parser')

    # try to extract team names from the page header - NOWE SELEKTORY
    try:
        # Nowa struktura Livesport (2025)
        home_el = soup.select_one("div.smv__participantRow.smv__homeParticipant a.participant__participantName")
        if not home_el:
            home_el = soup.select_one("a.participant__participantName")
        if home_el:
            out['home_team'] = home_el.get_text(strip=True)
    except Exception:
        pass

    try:
        away_el = soup.select_one("div.smv__participantRow.smv__awayParticipant a.participant__participantName")
        if not away_el:
            # Fallback: weÅº drugÄ… nazwÄ™ druÅ¼yny
            all_teams = soup.select("a.participant__participantName")
            if len(all_teams) >= 2:
                away_el = all_teams[1]
        if away_el:
            out['away_team'] = away_el.get_text(strip=True)
    except Exception:
        pass
    
    # WydobÄ…dÅº datÄ™ i godzinÄ™ meczu
    try:
        # Szukaj rÃ³Å¼nych moÅ¼liwych selektorÃ³w dla daty/czasu
        # PrÃ³ba 1: Element z czasem startu
        time_el = soup.select_one("div.duelParticipant__startTime")
        if time_el:
            out['match_time'] = time_el.get_text(strip=True)
        
        # PrÃ³ba 2: Z tytuÅ‚u strony (czÄ™sto zawiera datÄ™)
        if not out['match_time'] and soup.title:
            title = soup.title.string
            # Szukaj wzorca daty i czasu w tytule
            import re
            # Format: DD.MM.YYYY HH:MM lub podobne
            date_match = re.search(r'(\d{1,2}\.\d{1,2}\.\d{2,4})\s*(\d{1,2}:\d{2})?', title)
            if date_match:
                date_str = date_match.group(1)
                time_str = date_match.group(2) if date_match.group(2) else ''
                out['match_time'] = f"{date_str} {time_str}".strip()
        
        # PrÃ³ba 3: Z URL (moÅ¼e zawieraÄ‡ datÄ™)
        if not out['match_time']:
            # Czasem data jest w parametrach URL
            if 'date=' in url:
                import re
                date_param = re.search(r'date=([^&]+)', url)
                if date_param:
                    out['match_time'] = date_param.group(1)
    except Exception:
        pass

    # parse H2H
    h2h = parse_h2h_from_soup(soup, out['home_team'] or '')
    out['h2h_last5'] = h2h
    
    # WyciÄ…gnij datÄ™ ostatniego meczu H2H (pierwszy element)
    if h2h and len(h2h) > 0:
        out['last_h2h_date'] = h2h[0].get('date', None)

    # count home AND away wins in H2H list
    # WAÅ»NE: W zaleÅ¼noÅ›ci od trybu (away_team_focus), liczymy zwyciÄ™stwa gospodarzy lub goÅ›ci
    cnt_home = 0
    cnt_away = 0
    current_home = out['home_team']
    current_away = out['away_team']
    
    for item in h2h:
        try:
            # Pobierz nazwy druÅ¼yn i wynik z H2H meczu
            h2h_home = item.get('home', '').strip()
            h2h_away = item.get('away', '').strip()
            score = item.get('score', '')
            
            # Parsuj wynik
            import re
            score_match = re.search(r"(\d+)\s*[:\-]\s*(\d+)", score)
            if not score_match:
                continue
            
            goals_home_side = int(score_match.group(1))
            goals_away_side = int(score_match.group(2))
            
            # SprawdÅº ktÃ³ry zespÃ³Å‚ wygraÅ‚ w tamtym meczu H2H
            if goals_home_side > goals_away_side:
                winner_team = h2h_home
            elif goals_away_side > goals_home_side:
                winner_team = h2h_away
            else:
                winner_team = None  # remis
            
            # Teraz sprawdÅº czy zwyciÄ™zcÄ… byÅ‚ AKTUALNY GOSPODARZ
            if winner_team and current_home:
                winner_normalized = winner_team.lower().strip()
                current_home_normalized = current_home.lower().strip()
                
                if (winner_normalized == current_home_normalized or 
                    winner_normalized in current_home_normalized or 
                    current_home_normalized in winner_normalized):
                    cnt_home += 1
            
            # Teraz sprawdÅº czy zwyciÄ™zcÄ… byli AKTUALNI GOÅšCIE
            if winner_team and current_away:
                winner_normalized = winner_team.lower().strip()
                current_away_normalized = current_away.lower().strip()
                
                if (winner_normalized == current_away_normalized or 
                    winner_normalized in current_away_normalized or 
                    current_away_normalized in winner_normalized):
                    cnt_away += 1
                    
        except Exception as e:
            # Fallback: uÅ¼yj starej heurystyki
            if item.get('winner') == 'home' and current_home:
                h2h_home = item.get('home', '').lower().strip()
                if current_home.lower().strip() in h2h_home or h2h_home in current_home.lower().strip():
                    cnt_home += 1
            if item.get('winner') == 'away' and current_away:
                h2h_away = item.get('away', '').lower().strip()
                if current_away.lower().strip() in h2h_away or h2h_away in current_away.lower().strip():
                    cnt_away += 1

    out['home_wins_in_h2h_last5'] = cnt_home
    out['away_wins_in_h2h_last5'] = cnt_away
    out['h2h_count'] = len(h2h)
    
    # NOWE KRYTERIUM: W zaleÅ¼noÅ›ci od trybu, sprawdzamy gospodarzy lub goÅ›ci
    if away_team_focus:
        # Tryb GOÅšCIE: GoÅ›cie wygrali â‰¥60% meczÃ³w H2H
        win_rate = (cnt_away / len(h2h)) if len(h2h) > 0 else 0.0
        out['win_rate'] = win_rate
        basic_qualifies = win_rate >= 0.60 and len(h2h) >= 1
    else:
        # Tryb GOSPODARZE (domyÅ›lny): Gospodarze wygrali â‰¥60% meczÃ³w H2H
        win_rate = (cnt_home / len(h2h)) if len(h2h) > 0 else 0.0
        out['win_rate'] = win_rate
        basic_qualifies = win_rate >= 0.60 and len(h2h) >= 1
    
    # FORMA DRUÅ»YN: Dodaj pola dla zaawansowanej analizy
    out['home_form'] = []  # Forma ogÃ³lna (stara metoda)
    out['away_form'] = []
    out['home_form_overall'] = []  # NOWE: Forma z H2H overall
    out['home_form_home'] = []     # NOWE: Forma u siebie
    out['away_form_overall'] = []  # NOWE: Forma z H2H overall
    out['away_form_away'] = []     # NOWE: Forma na wyjeÅºdzie
    out['form_advantage'] = False  # NOWE: Czy gospodarze majÄ… przewagÄ™ formy?
    
    # JEÅšLI PODSTAWOWO SIÄ˜ KWALIFIKUJE - sprawdÅº zaawansowanÄ… formÄ™
    if basic_qualifies:
        team_name = out['away_team'] if away_team_focus else out['home_team']
        print(f"   ðŸ“Š Podstawowo kwalifikuje ({'GOÅšCIE' if away_team_focus else 'GOSPODARZE'}: {team_name}, H2H: {win_rate*100:.0f}%) - sprawdzam formÄ™...")
        try:
            # ZAAWANSOWANA ANALIZA FORMY (3 ÅºrÃ³dÅ‚a)
            advanced_form = extract_advanced_team_form(url, driver)
            
            out['home_form_overall'] = advanced_form['home_form_overall']
            out['home_form_home'] = advanced_form['home_form_home']
            out['away_form_overall'] = advanced_form['away_form_overall']
            out['away_form_away'] = advanced_form['away_form_away']
            
            # W trybie away_team_focus, przewaga formy to GOÅšCIE w dobrej formie i GOSPODARZE w sÅ‚abej
            if away_team_focus:
                out['form_advantage'] = advanced_form.get('away_advantage', False)
            else:
                out['form_advantage'] = advanced_form['form_advantage']
            
            # Dla kompatybilnoÅ›ci wstecznej - ustaw starÄ… formÄ™
            out['home_form'] = advanced_form['home_form_overall']
            out['away_form'] = advanced_form['away_form_overall']
            
            # FINALNE KRYTERIUM: H2H â‰¥60% (podstawowe)
            # Forma jest BONUSEM (dodatkowa ikona ðŸ”¥), nie wymogiem
            out['qualifies'] = basic_qualifies
            
            if out['form_advantage']:
                if away_team_focus:
                    print(f"   âœ… KWALIFIKUJE + PRZEWAGA FORMY GOÅšCI! ðŸ”¥")
                else:
                    print(f"   âœ… KWALIFIKUJE + PRZEWAGA FORMY GOSPODARZY! ðŸ”¥")
                print(f"      Home ogÃ³Å‚em: {format_form(advanced_form['home_form_overall'])}")
                print(f"      Home u siebie: {format_form(advanced_form['home_form_home'])}")
                print(f"      Away ogÃ³Å‚em: {format_form(advanced_form['away_form_overall'])}")
                print(f"      Away na wyjeÅºdzie: {format_form(advanced_form['away_form_away'])}")
            elif advanced_form['home_form_overall'] or advanced_form['away_form_overall']:
                print(f"   âœ… KWALIFIKUJE (forma dostÄ™pna, ale brak przewagi)")
                print(f"      Home ogÃ³Å‚em: {format_form(advanced_form['home_form_overall'])}")
                if advanced_form['home_form_home']:
                    print(f"      Home u siebie: {format_form(advanced_form['home_form_home'])}")
                print(f"      Away ogÃ³Å‚em: {format_form(advanced_form['away_form_overall'])}")
                if advanced_form['away_form_away']:
                    print(f"      Away na wyjeÅºdzie: {format_form(advanced_form['away_form_away'])}")
            else:
                print(f"   âœ… KWALIFIKUJE (brak danych formy - tylko H2H)")
                
        except Exception as e:
            print(f"   âš ï¸ BÅ‚Ä…d analizy formy: {e}")
            # Fallback - uÅ¼ywamy starego kryterium
            out['qualifies'] = basic_qualifies
            # Pobierz formÄ™ starÄ… metodÄ…
            try:
                home_form = extract_team_form(soup, driver, 'home', out.get('home_team'))
                away_form = extract_team_form(soup, driver, 'away', out.get('away_team'))
                out['home_form'] = home_form
                out['away_form'] = away_form
            except:
                pass
    else:
        # Nie kwalifikuje siÄ™ podstawowo - nie sprawdzaj formy
        out['qualifies'] = False
    
    # Kursy bukmacherskie - dodatkowa informacja (NIE wpÅ‚ywa na scoring!)
    odds = extract_betting_odds(soup)
    out['home_odds'] = odds['home_odds']
    out['away_odds'] = odds['away_odds']

    # FOREBET PREDICTIONS - TYLKO jeÅ›li mecz KWALIFIKUJE SIÄ˜!
    # ðŸ”¥ OPTYMALIZACJA: Skip Forebet dla meczÃ³w ktÃ³re i tak nie przejdÄ…
    if use_forebet and FOREBET_AVAILABLE and out.get('qualifies') and out.get('home_team') and out.get('away_team'):
        try:
            print(f"      ðŸŽ¯ Forebet: Pobieram predykcjÄ™...")
            
            # WyciÄ…gnij datÄ™ meczu z match_time (format: DD.MM.YY HH:MM lub DD.MM.YYYY HH:MM)
            from datetime import datetime as dt_forebet
            match_date_str = dt_forebet.now().strftime('%Y-%m-%d')  # DomyÅ›lna data = dzisiaj
            if out.get('match_time'):
                try:
                    import re
                    # ObsÅ‚uga zarÃ³wno DD.MM.YY jak i DD.MM.YYYY
                    date_match = re.search(r'(\d{2})\.(\d{2})\.(\d{2,4})', out['match_time'])
                    if date_match:
                        day, month, year = date_match.groups()
                        # JeÅ›li rok ma 4 cyfry, uÅ¼yj go bezpoÅ›rednio
                        if len(year) == 4:
                            match_date_str = f'{year}-{month}-{day}'
                        else:
                            # Rok 2-cyfrowy: 00-50 -> 2000s, 51-99 -> 1900s
                            year_int = int(year)
                            full_year = 2000 + year_int if year_int <= 50 else 1900 + year_int
                            match_date_str = f'{full_year}-{month}-{day}'
                except:
                    pass
            
            forebet_result = search_forebet_prediction(
                home_team=out['home_team'],
                away_team=out['away_team'],
                match_date=match_date_str,
                driver=driver,  # ReuÅ¼ywamy tego samego drivera
                sport=sport,
                headless=False  # Forebet wymaga visible mode
            )
            
            if forebet_result.get('success'):
                out['forebet_prediction'] = forebet_result.get('prediction')
                out['forebet_probability'] = forebet_result.get('probability')
                out['forebet_exact_score'] = forebet_result.get('exact_score')
                out['forebet_over_under'] = forebet_result.get('over_under')
                out['forebet_btts'] = forebet_result.get('btts')
                out['forebet_avg_goals'] = forebet_result.get('avg_goals')
                
                print(f"      âœ… {format_forebet_result(forebet_result)}")
            else:
                print(f"      âš ï¸ Forebet: {forebet_result.get('error', 'Brak predykcji')}")
                
        except Exception as e:
            print(f"      âš ï¸ BÅ‚Ä…d Forebet: {e}")
    
    # ============================================
    # GEMINI AI ANALYSIS (Faza 3)
    # ============================================
    if use_gemini and out.get('qualifies'):
        try:
            print("      ðŸ¤– Gemini AI analysis...")
            
            # Przygotuj dane dla AI
            h2h_data = {
                'home_wins': out.get('home_wins_in_h2h_last5', 0),
                'away_wins': out.get('away_wins_in_h2h_last5', 0),
                'total': out.get('h2h_count', 5)
            }
            
            # Forma jako string (np. "7/10")
            home_form_str = format_form_as_score(out.get('home_form', []))
            away_form_str = format_form_as_score(out.get('away_form', []))
            
            # Forebet prediction string
            forebet_str = None
            if out.get('forebet_prediction') and out.get('forebet_probability'):
                forebet_str = f"{out['forebet_prediction']} ({out['forebet_probability']:.1f}%)"
                if out.get('forebet_exact_score'):
                    forebet_str += f" - {out['forebet_exact_score']}"
            
            # WywoÅ‚aj Gemini AI (lazy load)
            if lazy_load_gemini():
                gemini_result = gemini_analyze_match(
                    home_team=out.get('home_team', 'Unknown'),
                    away_team=out.get('away_team', 'Unknown'),
                    sport=sport,
                    h2h_data=h2h_data,
                    home_form=home_form_str,
                    away_form=away_form_str,
                    forebet_prediction=forebet_str,
                    home_odds=out.get('home_odds'),
                    away_odds=out.get('away_odds'),
                    additional_info=f"Last H2H: {out.get('last_h2h_date', 'N/A')}"
                )
                
                # Zapisz wyniki
                if not gemini_result.get('error'):
                    out['gemini_prediction'] = gemini_result.get('prediction')
                    out['gemini_confidence'] = gemini_result.get('confidence')
                    out['gemini_reasoning'] = gemini_result.get('reasoning')
                    out['gemini_recommendation'] = gemini_result.get('recommendation')
                    
                    print(f"      âœ… AI: {gemini_result.get('prediction', '')[:60]}... ({gemini_result.get('confidence', 0)}%)")
                else:
                    print(f"      âš ï¸ Gemini AI: {gemini_result.get('error', 'Unknown error')}")
            else:
                print(f"      âš ï¸ Gemini AI niedostÄ™pne - pominiÄ™to")
                
        except Exception as e:
            print(f"      âš ï¸ BÅ‚Ä…d Gemini AI: {e}")
    
    # ========================================================================
    # SOFASCORE INTEGRATION - "Who will win?" predictions
    # ========================================================================
    if use_sofascore:
        try:
            print(f"   ðŸŽ¯ SofaScore: Pobieranie predykcji...")
            from sofascore_scraper import scrape_sofascore_full
            
            sofascore_result = scrape_sofascore_full(
                driver=driver,
                home_team=out['home_team'],
                away_team=out['away_team'],
                sport=sport
            )
            
            if sofascore_result.get('sofascore_found'):
                # Dodaj dane SofaScore do wyniku
                out['sofascore_home_win_prob'] = sofascore_result.get('sofascore_home_win_prob')
                out['sofascore_draw_prob'] = sofascore_result.get('sofascore_draw_prob')
                out['sofascore_away_win_prob'] = sofascore_result.get('sofascore_away_win_prob')
                out['sofascore_total_votes'] = sofascore_result.get('sofascore_total_votes', 0)
                out['sofascore_home_odds_avg'] = sofascore_result.get('sofascore_home_odds_avg')
                out['sofascore_away_odds_avg'] = sofascore_result.get('sofascore_away_odds_avg')
                out['sofascore_url'] = sofascore_result.get('sofascore_url')
                
                print(f"      âœ… SofaScore: Home={sofascore_result.get('sofascore_home_win_prob')}%, "
                      f"Away={sofascore_result.get('sofascore_away_win_prob')}%, "
                      f"Votes={sofascore_result.get('sofascore_total_votes', 0)}")
            else:
                print(f"      âš ï¸ SofaScore: Mecz nie znaleziony")
                
        except ImportError:
            print(f"      âš ï¸ SofaScore scraper nie zainstalowany")
        except Exception as e:
            print(f"      âš ï¸ BÅ‚Ä…d SofaScore: {e}")
    
    # FLASHSCORE ODDS
    if use_flashscore and FLASHSCORE_AVAILABLE and out.get('qualifies') and out.get('home_team') and out.get('away_team'):
        try:
            print(f"   ðŸ’° FlashScore: Pobieranie kursÃ³w...")
            
            flashscore_scraper = FlashScoreOddsScraper(headless=True)
            flashscore_result = flashscore_scraper.get_odds(
                home_team=out['home_team'],
                away_team=out['away_team'],
                sport=sport,
                driver=driver  # ReuÅ¼ywamy istniejÄ…cego drivera
            )
            
            if flashscore_result.get('found'):
                out['flashscore_home_odds'] = flashscore_result.get('home_odds')
                out['flashscore_draw_odds'] = flashscore_result.get('draw_odds')
                out['flashscore_away_odds'] = flashscore_result.get('away_odds')
                out['flashscore_over_25'] = flashscore_result.get('over_25_odds')
                out['flashscore_under_25'] = flashscore_result.get('under_25_odds')
                out['flashscore_bookmaker'] = flashscore_result.get('bookmaker', 'FlashScore')
                out['flashscore_found'] = True
                
                # Fallback: jeÅ›li nie mamy home_odds/away_odds z Livesport, uÅ¼yj FlashScore
                if not out.get('home_odds') and flashscore_result.get('home_odds'):
                    out['home_odds'] = flashscore_result.get('home_odds')
                if not out.get('away_odds') and flashscore_result.get('away_odds'):
                    out['away_odds'] = flashscore_result.get('away_odds')
                
                print(f"      âœ… FlashScore: {flashscore_result.get('home_odds')}/{flashscore_result.get('draw_odds')}/{flashscore_result.get('away_odds')}")
            else:
                print(f"      âš ï¸ FlashScore: Kursy nie znalezione")
                out['flashscore_found'] = False
                
        except Exception as e:
            print(f"      âš ï¸ BÅ‚Ä…d FlashScore: {e}")
            out['flashscore_found'] = False
    elif use_flashscore and not FLASHSCORE_AVAILABLE:
        print(f"      âš ï¸ FlashScore: Scraper niedostÄ™pny")

    return out


def format_form(form_list: List[str]) -> str:
    """
    Formatuje listÄ™ formy do Å‚adnego stringa z emoji.
    
    Args:
        form_list: ['W', 'L', 'D', 'W', 'W']
    
    Returns:
        'Wâœ… LâŒ DðŸŸ¡ Wâœ… Wâœ…'
    """
    emoji_map = {'W': 'âœ…', 'L': 'âŒ', 'D': 'ðŸŸ¡'}
    return ' '.join([f"{r}{emoji_map.get(r, '')}" for r in form_list])


def format_form_as_score(form_list: List[str]) -> str:
    """
    Konwertuje formÄ™ na score (np. 7/10 dla Gemini AI)
    
    Args:
        form_list: ['W', 'L', 'D', 'W', 'W']
    
    Returns:
        '7/10' (3 wins * 3 + 1 draw * 1 = 10, scale to /10)
    """
    if not form_list:
        return 'N/A'
    
    wins = form_list.count('W')
    draws = form_list.count('D')
    total = len(form_list)
    
    # Scoring: Win=3pts, Draw=1pt, Loss=0pt
    points = wins * 3 + draws * 1
    max_points = total * 3
    
    # Scale to /10
    if max_points > 0:
        score = round((points / max_points) * 10, 1)
        return f"{score}/10"
    
    return 'N/A'


def extract_advanced_team_form(match_url: str, driver: webdriver.Chrome) -> Dict:
    """
    Ekstraktuje zaawansowanÄ… formÄ™ druÅ¼yn z 3 ÅºrÃ³deÅ‚:
    1. Forma ogÃ³lna (ostatnie 5 meczÃ³w)
    2. Forma u siebie (gospodarze)
    3. Forma na wyjeÅºdzie (goÅ›cie)
    
    Returns:
        {
            'home_form_overall': ['W', 'L', 'D', 'W', 'W'],
            'home_form_home': ['W', 'W', 'W', 'D', 'W'],  # Forma gospodarzy u siebie
            'away_form_overall': ['L', 'L', 'W', 'L', 'D'],
            'away_form_away': ['L', 'L', 'L', 'D', 'L'],  # Forma goÅ›ci na wyjeÅºdzie
            'form_advantage': True/False  # Czy gospodarze majÄ… przewagÄ™?
        }
    """
    result = {
        'home_form_overall': [],
        'home_form_home': [],
        'away_form_overall': [],
        'away_form_away': [],
        'form_advantage': False
    }
    
    try:
        # Konwertuj URL meczu na URL H2H
        # Z: /mecz/pilka-nozna/team1/team2/?mid=XXX
        # Na: /mecz/pilka-nozna/team1/team2/h2h/ogolem/?mid=XXX (lub /u-siebie/, /na-wyjezdzie/)
        
        if '/match/' in match_url or '/mecz/' in match_url:
            base_url = match_url.split('?')[0]  # UsuÅ„ query params
            
            # UsuÅ„ koÅ„cÃ³wkÄ™ "/szczegoly" lub innÄ… stronÄ™, jeÅ›li istnieje
            base_url = base_url.rstrip('/')
            if base_url.endswith('/szczegoly') or base_url.endswith('/szczegoly/'):
                base_url = base_url.replace('/szczegoly', '')
            
            mid = match_url.split('mid=')[1] if 'mid=' in match_url else ''
            
            # 1. FORMA OGÃ“LNA
            h2h_overall_url = f"{base_url}/h2h/ogolem/?mid={mid}"
            result['home_form_overall'], result['away_form_overall'] = _extract_form_from_h2h_page(
                h2h_overall_url, driver, 'overall'
            )
            
            # 2. FORMA U SIEBIE (gospodarze)
            h2h_home_url = f"{base_url}/h2h/u-siebie/?mid={mid}"
            result['home_form_home'], _ = _extract_form_from_h2h_page(
                h2h_home_url, driver, 'home'
            )
            
            # 3. FORMA NA WYJEÅ¹DZIE (goÅ›cie)
            # NOWA METODA: Pobierz dane z strony ogÃ³lnej H2H i filtruj mecze goÅ›ci na wyjeÅºdzie
            result['away_form_away'] = _extract_away_form_from_overall(
                h2h_overall_url, driver, result['away_form_overall']
            )
            
            # 4. ANALIZA PRZEWAGI FORMY
            result['form_advantage'] = _analyze_form_advantage(result)
            # 5. ANALIZA PRZEWAGI GOÅšCI (dla trybu away_team_focus)
            result['away_advantage'] = _analyze_away_form_advantage(result)
            
    except Exception as e:
        print(f"   âš ï¸ extract_advanced_team_form error: {e}")
    
    return result


def _extract_form_from_h2h_page(url: str, driver: webdriver.Chrome, context: str) -> tuple:
    """
    Pomocnicza funkcja do ekstraktowania formy z konkretnej strony H2H.
    
    Args:
        url: URL strony H2H
        driver: Selenium WebDriver
        context: 'overall', 'home', lub 'away'
    
    Returns:
        (home_form, away_form) - kaÅ¼da to lista ['W', 'L', 'D', ...]
    """
    home_form = []
    away_form = []
    
    try:
        driver.get(url)
        time.sleep(3.0)  # Czas na zaÅ‚adowanie dynamicznych elementÃ³w
        
        # Scroll down to trigger lazy-loading content
        try:
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(1.0)
        except:
            pass
        
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        
        # DEBUG: SprawdÅº czy strona siÄ™ zaÅ‚adowaÅ‚a
        page_text = soup.get_text()
        if 'error' in page_text.lower() or 'can\'t be displayed' in page_text.lower():
            print(f"      âš ï¸ Strona {context} zwrÃ³ciÅ‚a bÅ‚Ä…d (404?) - URL moÅ¼e byÄ‡ niepoprawny")
            return ([], [])
        
        # NOWA METODA 1: Ekstraktuj formy z sekcji h2h__section
        # Livesport organizuje dane w sekcje: pierwsza sekcja = home, druga = away
        h2h_sections = soup.find_all('div', class_='h2h__section')
        
        for idx, section in enumerate(h2h_sections[:2]):  # Pierwsze 2 sekcje (home, away)
            # METODA 1A: Szukaj form badges z rÃ³Å¼nymi klasami (LiveSport zmienia je)
            badges = section.find_all('div', class_=lambda c: c and 'badgeform' in c.lower() if c else False)
            
            # METODA 1B: Alternatywne selektory
            if not badges:
                badges = section.select('div[class*="form"], span[class*="form"]')
            
            temp_form = []
            for badge in badges[:5]:  # Max 5 wynikÃ³w
                text = badge.get_text().strip()
                title = badge.get('title', '')
                
                # Konwersja: Z->W, R->D, P->L (polskie oznaczenia)
                if 'Zwyci' in title or text == 'Z' or text == 'W':
                    temp_form.append('W')
                elif 'Remis' in title or text == 'R' or text == 'D':
                    temp_form.append('D')
                elif 'Pora' in title or text == 'P' or text == 'L':
                    temp_form.append('L')
            
            # Przypisz do home (idx=0) lub away (idx=1)
            if idx == 0:
                home_form = temp_form
            elif idx == 1:
                away_form = temp_form
        
        # FALLBACK METODA 2: JeÅ›li badges nie zadziaÅ‚aÅ‚y, analizuj wiersze z wynikami
        if (not home_form and not away_form) or (len(home_form) == 0 and len(away_form) == 0):
            # Szukaj wierszy z meczami w sekcjach H2H
            for idx, section in enumerate(h2h_sections[:2]):
                match_rows = section.select('a.h2h__row')
                
                temp_form = []
                for row in match_rows[:5]:
                    try:
                        # Pobierz wynik
                        result_spans = row.select('span.h2h__result span')
                        if len(result_spans) >= 2:
                            score_home = int(result_spans[0].get_text(strip=True))
                            score_away = int(result_spans[1].get_text(strip=True))
                            
                            # idx=0 to forma gospodarzy, idx=1 to forma goÅ›ci
                            if idx == 0:  # Sekcja gospodarzy
                                if score_home > score_away:
                                    temp_form.append('W')
                                elif score_away > score_home:
                                    temp_form.append('L')
                                else:
                                    temp_form.append('D')
                            else:  # Sekcja goÅ›ci
                                if score_away > score_home:
                                    temp_form.append('W')
                                elif score_home > score_away:
                                    temp_form.append('L')
                                else:
                                    temp_form.append('D')
                    except:
                        continue
                
                if idx == 0:
                    home_form = temp_form
                elif idx == 1:
                    away_form = temp_form
        
        # FALLBACK METODA 3: Stara metoda analizy wierszy
        if (not home_form and not away_form) or (len(home_form) == 0 and len(away_form) == 0):
            h2h_rows = soup.select('div.h2h__row, tr.h2h')
            
            for row in h2h_rows[:5]:
                # SprawdÅº wynik meczu
                score_elem = row.select_one('div[class*="score"], span[class*="score"]')
                if score_elem:
                    score_text = score_elem.get_text(strip=True)
                    # Format: "3:1" lub "1:0"
                    if ':' in score_text or '-' in score_text:
                        try:
                            separator = ':' if ':' in score_text else '-'
                            home_score, away_score = map(int, score_text.split(separator))
                            if home_score > away_score:
                                home_form.append('W')
                                away_form.append('L')
                            elif away_score > home_score:
                                home_form.append('L')
                                away_form.append('W')
                            else:
                                home_form.append('D')
                                away_form.append('D')
                        except:
                            continue
                            
    except Exception as e:
        print(f"      âš ï¸ _extract_form_from_h2h_page error ({context}): {e}")
    
    return (home_form[:5], away_form[:5])


def _extract_away_form_from_overall(url: str, driver: webdriver.Chrome, away_form_overall: List[str]) -> List[str]:
    """
    Ekstraktuje formÄ™ goÅ›ci NA WYJEÅ¹DZIE z ogÃ³lnej strony H2H.
    Analizuje wiersze meczÃ³w i sprawdza ktÃ³ry mecz byÅ‚ rozgrywany na wyjeÅºdzie.
    
    Args:
        url: URL strony H2H ogÃ³Å‚em
        driver: Selenium WebDriver
        away_form_overall: OgÃ³lna forma goÅ›ci (jako fallback)
    
    Returns:
        Lista formy na wyjeÅºdzie ['W', 'L', 'D', ...] lub away_form_overall jeÅ›li nie moÅ¼na pobraÄ‡
    """
    away_form_away = []
    
    try:
        # Strona jest juÅ¼ zaÅ‚adowana z wczeÅ›niejszego wywoÅ‚ania, ale dla pewnoÅ›ci odÅ›wieÅ¼
        driver.get(url)
        time.sleep(2.0)
        
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        
        # Szukaj drugiej sekcji H2H (sekcja goÅ›ci)
        h2h_sections = soup.find_all('div', class_='h2h__section')
        
        if len(h2h_sections) >= 2:
            away_section = h2h_sections[1]  # Druga sekcja = goÅ›cie
            
            # ZnajdÅº wiersze meczÃ³w
            match_rows = away_section.select('a.h2h__row')
            
            for row in match_rows[:5]:
                try:
                    # Pobierz nazwy druÅ¼yn
                    home_el = row.select_one('span.h2h__homeParticipant span.h2h__participantInner')
                    away_el = row.select_one('span.h2h__awayParticipant span.h2h__participantInner')
                    
                    home_name = home_el.get_text(strip=True) if home_el else ''
                    away_name = away_el.get_text(strip=True) if away_el else ''
                    
                    # Pobierz wynik
                    result_spans = row.select('span.h2h__result span')
                    if len(result_spans) >= 2:
                        score_home = int(result_spans[0].get_text(strip=True))
                        score_away = int(result_spans[1].get_text(strip=True))
                        
                        # Sekcja goÅ›ci pokazuje mecze gdzie aktualny goÅ›Ä‡ graÅ‚
                        # Musimy sprawdziÄ‡ czy w TYM meczu byÅ‚ on GOÅšCIEM czy GOSPODARZEM
                        # JeÅ›li away_name jest w nazwie current_away_team (z main match), to byÅ‚ goÅ›ciem
                        
                        # Prostsza metoda: patrz na wynik z perspektywy away_name
                        # JeÅ›li away_name = away w h2h_row -> byÅ‚ goÅ›ciem
                        # MoÅ¼emy to poznaÄ‡ po pozycji (right side)
                        
                        # ZAKÅADAMY Å¼e w sekcji goÅ›ci, mecze sÄ… pokazane z perspektywy goÅ›cia
                        # wiÄ™c score_away to jego wynik
                        if score_away > score_home:
                            away_form_away.append('W')
                        elif score_home > score_away:
                            away_form_away.append('L')
                        else:
                            away_form_away.append('D')
                            
                except Exception as e:
                    continue
        
        # JeÅ›li nie znaleziono danych, uÅ¼yj formy ogÃ³lnej jako fallback
        if not away_form_away and away_form_overall:
            return away_form_overall[:5]
        
    except Exception as e:
        print(f"      âš ï¸ _extract_away_form_from_overall error: {e}")
        return away_form_overall[:5] if away_form_overall else []
    
    return away_form_away[:5]


def _analyze_form_advantage(form_data: Dict) -> bool:
    """
    Analizuje czy gospodarze majÄ… przewagÄ™ w formie.
    
    Kryteria:
    - Gospodarze w dobrej formie (wiÄ™cej W+D niÅ¼ L)
    - GoÅ›cie w sÅ‚abej formie (wiÄ™cej L niÅ¼ W+D)
    - Gospodarze lepsi od goÅ›ci
    
    Returns:
        True jeÅ›li gospodarze majÄ… przewagÄ™
    """
    try:
        # Oblicz punkty formy (W=3, D=1, L=0)
        def form_points(form_list):
            points = 0
            for result in form_list:
                if result == 'W':
                    points += 3
                elif result == 'D':
                    points += 1
            return points
        
        # Forma ogÃ³lna
        home_overall_pts = form_points(form_data['home_form_overall'])
        away_overall_pts = form_points(form_data['away_form_overall'])
        
        # Forma kontekstowa (u siebie/na wyjeÅºdzie)
        home_home_pts = form_points(form_data['home_form_home'])
        away_away_pts = form_points(form_data['away_form_away'])
        
        # Przewaga jeÅ›li:
        # 1. Gospodarze majÄ… wiÄ™cej punktÃ³w (ogÃ³Å‚em)
        # 2. Gospodarze u siebie > GoÅ›cie na wyjeÅºdzie
        # 3. Gospodarze w dobrej formie (>= 7 pkt z 15 moÅ¼liwych)
        
        home_good_form = home_overall_pts >= 7  # >= 2.3 pkt/mecz
        away_poor_form = away_overall_pts <= 6   # <= 1.2 pkt/mecz
        
        home_better = (home_overall_pts > away_overall_pts and 
                      home_home_pts > away_away_pts)
        
        return (home_good_form and away_poor_form) or home_better
        
    except Exception:
        return False


def _analyze_away_form_advantage(form_data: Dict) -> bool:
    """
    Analizuje czy GOÅšCIE majÄ… przewagÄ™ w formie.
    
    Kryteria (odwrotne niÅ¼ dla gospodarzy):
    - GoÅ›cie w dobrej formie (wiÄ™cej W+D niÅ¼ L)
    - Gospodarze w sÅ‚abej formie (wiÄ™cej L niÅ¼ W+D)
    - GoÅ›cie lepsi od gospodarzy
    
    Returns:
        True jeÅ›li goÅ›cie majÄ… przewagÄ™
    """
    try:
        # Oblicz punkty formy (W=3, D=1, L=0)
        def form_points(form_list):
            points = 0
            for result in form_list:
                if result == 'W':
                    points += 3
                elif result == 'D':
                    points += 1
            return points
        
        # Forma ogÃ³lna
        home_overall_pts = form_points(form_data['home_form_overall'])
        away_overall_pts = form_points(form_data['away_form_overall'])
        
        # Forma kontekstowa (u siebie/na wyjeÅºdzie)
        home_home_pts = form_points(form_data['home_form_home'])
        away_away_pts = form_points(form_data['away_form_away'])
        
        # Przewaga GOÅšCI jeÅ›li:
        # 1. GoÅ›cie majÄ… wiÄ™cej punktÃ³w (ogÃ³Å‚em)
        # 2. GoÅ›cie na wyjeÅºdzie > Gospodarze u siebie
        # 3. GoÅ›cie w dobrej formie (>= 7 pkt z 15 moÅ¼liwych)
        
        away_good_form = away_overall_pts >= 7  # >= 2.3 pkt/mecz
        home_poor_form = home_overall_pts <= 6   # <= 1.2 pkt/mecz
        
        away_better = (away_overall_pts > home_overall_pts and 
                      away_away_pts > home_home_pts)
        
        return (away_good_form and home_poor_form) or away_better
        
    except Exception:
        return False


def extract_team_form(soup: BeautifulSoup, driver: webdriver.Chrome, side: str, team_name: str) -> List[str]:
    """
    Ekstraktuje formÄ™ druÅ¼yny (ostatnie 5 meczÃ³w: W/L/D).
    
    Args:
        soup: BeautifulSoup object strony meczu
        driver: Selenium WebDriver
        side: 'home' lub 'away'
        team_name: Nazwa druÅ¼yny
    
    Returns:
        Lista wynikÃ³w: ['W', 'W', 'L', 'D', 'W'] (od najnowszego do najstarszego)
    """
    form = []
    
    try:
        # METODA 1: Szukaj elementÃ³w formy na stronie (ikony W/L/D)
        # Livesport czÄ™sto ma elementy z klasami typu "form__cell--win", "form__cell--loss", etc.
        
        if side == 'home':
            form_selectors = [
                'div.smv__homeParticipant div[class*="form"]',
                'div.participant__form--home',
                'div[class*="homeForm"]'
            ]
        else:
            form_selectors = [
                'div.smv__awayParticipant div[class*="form"]',
                'div.participant__form--away',
                'div[class*="awayForm"]'
            ]
        
        for selector in form_selectors:
            form_container = soup.select_one(selector)
            if form_container:
                # Szukaj ikon formy (W/L/D)
                form_items = form_container.find_all(['div', 'span'], class_=re.compile(r'form.*cell|form.*item'))
                
                for item in form_items[:5]:  # Maksymalnie 5 ostatnich meczÃ³w
                    class_str = ' '.join(item.get('class', []))
                    
                    if 'win' in class_str.lower():
                        form.append('W')
                    elif 'loss' in class_str.lower() or 'lost' in class_str.lower():
                        form.append('L')
                    elif 'draw' in class_str.lower():
                        form.append('D')
                
                if form:
                    break
        
        # METODA 2: JeÅ›li nie znaleziono formy, parsuj z tytuÅ‚Ã³w/tekstÃ³w
        if not form:
            # Szukaj elementÃ³w z tekstem typu "W", "L", "D"
            all_text_elements = soup.find_all(['div', 'span'], string=re.compile(r'^[WLD]$'))
            for elem in all_text_elements[:5]:
                text = elem.get_text(strip=True).upper()
                if text in ['W', 'L', 'D']:
                    form.append(text)
        
        # METODA 3: Fallback - parsuj ostatnie mecze z H2H jako proxy formy
        if not form and team_name:
            # Pobierz ostatnie mecze druÅ¼yny (nie tylko H2H) z sekcji "form" lub "last matches"
            last_matches = soup.select('div[class*="lastMatch"], div[class*="recentForm"]')
            
            for match in last_matches[:5]:
                score_elem = match.find(string=re.compile(r'\d+\s*[-:]\s*\d+'))
                if score_elem:
                    score_match = re.search(r'(\d+)\s*[-:]\s*(\d+)', score_elem)
                    if score_match:
                        goals1 = int(score_match.group(1))
                        goals2 = int(score_match.group(2))
                        
                        if goals1 > goals2:
                            form.append('W')
                        elif goals2 > goals1:
                            form.append('L')
                        else:
                            form.append('D')
    
    except Exception as e:
        # JeÅ›li coÅ› pÃ³jdzie nie tak, zwrÃ³Ä‡ pustÄ… listÄ™
        pass
    
    # Ogranicz do 5 meczÃ³w
    return form[:5]


def extract_betting_odds(soup: BeautifulSoup) -> Dict[str, Optional[float]]:
    """
    Ekstraktuj kursy bukmacherskie dla meczu (jeÅ›li dostÄ™pne).
    
    Returns:
        {'home_odds': 1.85, 'away_odds': 2.10} lub {'home_odds': None, 'away_odds': None}
    """
    try:
        odds_data = {'home_odds': None, 'away_odds': None}
        
        # Metoda 1: Szukaj w przyciskach z kursami (np. <button class="*odds*">)
        odds_buttons = soup.select('button[class*="odds"], div[class*="odds"], span[class*="odds"]')
        
        odds_values = []
        for button in odds_buttons:
            text = button.get_text(strip=True)
            # Szukaj liczb typu 1.85, 2.10, etc.
            odds_match = re.findall(r'\d+\.\d{2}', text)
            if odds_match:
                odds_values.extend([float(o) for o in odds_match])
        
        # Metoda 2: Szukaj w data-attributes
        odds_elements = soup.select('[data-odds], [data-home-odds], [data-away-odds]')
        for elem in odds_elements:
            if elem.get('data-home-odds'):
                try:
                    odds_data['home_odds'] = float(elem.get('data-home-odds'))
                except:
                    pass
            if elem.get('data-away-odds'):
                try:
                    odds_data['away_odds'] = float(elem.get('data-away-odds'))
                except:
                    pass
        
        # Metoda 3: Szukaj w JSON-LD lub skryptach
        scripts = soup.find_all('script', type='application/ld+json')
        for script in scripts:
            try:
                data = json.loads(script.string)
                if 'offers' in data or 'odds' in str(data).lower():
                    # PrÃ³buj wydobyÄ‡ kursy z JSON
                    pass
            except:
                pass
        
        # JeÅ›li znaleÅºliÅ›my dokÅ‚adnie 2 kursy (home i away)
        if len(odds_values) >= 2 and odds_data['home_odds'] is None:
            odds_data['home_odds'] = odds_values[0]
            odds_data['away_odds'] = odds_values[1]
        
        return odds_data
        
    except Exception as e:
        print(f"   âš ï¸ extract_betting_odds error: {e}")
        return {'home_odds': None, 'away_odds': None}


def extract_player_ranking(soup: BeautifulSoup, player_name: str) -> Optional[int]:
    """
    WydobÄ…dÅº ranking zawodnika ze strony.
    
    Livesport przechowuje rankingi w JSON wbudowanym w HTML:
    "rank":["ATP","13","..."]
    """
    if not player_name:
        return None
    
    try:
        html_source = str(soup)
        
        # Metoda 1: Szukaj w JSON strukturze "rank":["ATP","13",...]
        # Pattern: "rank":\["(ATP|WTA)","(\d+)","
        rank_pattern = r'"rank":\["(ATP|WTA)","(\d+)",'
        matches = re.findall(rank_pattern, html_source, re.IGNORECASE)
        
        if len(matches) >= 2:
            # Mamy dwa rankingi - musimy okreÅ›liÄ‡ ktÃ³ry naleÅ¼y do ktÃ³rego zawodnika
            # SprawdÅºmy kolejnoÅ›Ä‡ nazwisk na stronie
            all_participants = soup.select('a.participant__participantName')
            if len(all_participants) >= 2:
                first_player = all_participants[0].get_text(strip=True)
                second_player = all_participants[1].get_text(strip=True)
                
                # SprawdÅº czy player_name pasuje do pierwszego czy drugiego
                player_normalized = player_name.lower().strip()
                first_normalized = first_player.lower().strip()
                second_normalized = second_player.lower().strip()
                
                if player_normalized in first_normalized or first_normalized in player_normalized:
                    # To pierwszy zawodnik - pierwszy ranking
                    return int(matches[0][1])  # matches[0][1] to numer rankingu
                elif player_normalized in second_normalized or second_normalized in player_normalized:
                    # To drugi zawodnik - drugi ranking
                    return int(matches[1][1])
        
        # Fallback: JeÅ›li jest tylko 1 ranking
        if len(matches) == 1:
            return int(matches[0][1])
        
        # Metoda 2 (Fallback): "ATP: 13" lub "WTA: 42" w tekÅ›cie
        text = soup.get_text()
        atp_wta_rankings = re.findall(r'(?:ATP|WTA):\s*(\d+)', text, re.IGNORECASE)
        
        if len(atp_wta_rankings) >= 2:
            all_participants = soup.select('a.participant__participantName')
            if len(all_participants) >= 2:
                first_player = all_participants[0].get_text(strip=True)
                second_player = all_participants[1].get_text(strip=True)
                
                player_normalized = player_name.lower().strip()
                first_normalized = first_player.lower().strip()
                second_normalized = second_player.lower().strip()
                
                if player_normalized in first_normalized or first_normalized in player_normalized:
                    return int(atp_wta_rankings[0])
                elif player_normalized in second_normalized or second_normalized in player_normalized:
                    return int(atp_wta_rankings[1])
        
        return None
    except Exception as e:
        print(f"   âš ï¸ extract_player_ranking error: {e}")
        return None


def detect_tennis_surface(soup: BeautifulSoup, url: str) -> Optional[str]:
    """
    Wykryj powierzchniÄ™ kortu z informacji o turnieju.
    
    Returns:
        'clay', 'grass', 'hard', lub None
    """
    try:
        text = soup.get_text().lower()
        url_lower = url.lower()
        
        # Metoda 1: Wykryj z elementÃ³w H2H na stronie
        # Livesport oznacza powierzchniÄ™ w klasach: 'clay', 'grass', 'hard'
        surface_elements = soup.select('[class*="surface"]')
        for el in surface_elements:
            classes = ' '.join(el.get('class', [])).lower()
            if 'clay' in classes or 'ziemna' in classes:
                return 'clay'
            if 'grass' in classes or 'trawiasta' in classes:
                return 'grass'
            if 'hard' in classes or 'twarda' in classes:
                return 'hard'
        
        # Metoda 2: SÅ‚owa kluczowe w tekÅ›cie/URL
        # Clay
        clay_keywords = [
            'clay', 'ziemia', 'ziemna', 'antuka', 'roland garros', 'french open',
            'monte carlo', 'rome', 'madrid', 'barcelona', 'hamburg',
            'roland-garros', 'glina'
        ]
        if any(kw in text or kw in url_lower for kw in clay_keywords):
            return 'clay'
        
        # Grass
        grass_keywords = [
            'grass', 'trawa', 'trawiasta', 'wimbledon', 'halle', 'queens', 
            's-hertogenbosch', 'eastbourne', 'mallorca'
        ]
        if any(kw in text or kw in url_lower for kw in grass_keywords):
            return 'grass'
        
        # Hard
        hard_keywords = [
            'hard', 'twarda', 'us open', 'australian open', 'usopen', 
            'australian', 'indian wells', 'miami', 'cincinnati', 
            'montreal', 'toronto', 'shanghai', 'beijing', 'paris masters',
            'szanghaj', 'pekin'
        ]
        if any(kw in text or kw in url_lower for kw in hard_keywords):
            return 'hard'
        
        # DomyÅ›lnie: hard (najczÄ™stsza powierzchnia)
        return 'hard'
    except Exception:
        return None


def extract_player_form_simple(soup: BeautifulSoup, player_name: str, h2h_matches: List[Dict]) -> List[str]:
    """
    WydobÄ…dÅº formÄ™ zawodnika (ostatnie wyniki).
    
    UÅ¼ywa H2H jako proxy - bierze ostatnie mecze zawodnika przeciwko WSZYSTKIM
    przeciwnikom i ekstraktuje W/L pattern.
    
    Returns:
        ['W', 'W', 'L', 'W', 'W']  # W=wygrana, L=przegrana
    """
    if not player_name:
        return []
    
    try:
        # METODA 1: Szukaj "form" badge/indicators na stronie Livesport
        # Czasami Livesport pokazuje formÄ™ jako serie W/L/D
        form_indicators = soup.select('div.form, span.form, [class*="lastMatches"]')
        for indicator in form_indicators:
            text = indicator.get_text(strip=True).upper()
            # Ekstraktuj tylko W/L/D
            form_chars = [c for c in text if c in ['W', 'L', 'D']]
            if len(form_chars) >= 3:  # Mamy przynajmniej 3 wyniki
                # Konwertuj D (draw) na L w tenisie
                return [('L' if c == 'D' else c) for c in form_chars[:5]]
        
        # METODA 2: UÅ¼yj H2H jako proxy (ostatnie mecze tego zawodnika)
        if not h2h_matches:
            # JeÅ›li brak H2H, symuluj przeciÄ™tnÄ… formÄ™ (3W/2L = 60%)
            return ['W', 'W', 'W', 'L', 'L']
        
        player_form = []
        player_normalized = player_name.lower().strip()
        
        # Przeiteruj przez H2H (to sÄ… mecze MIÄ˜DZY tymi dwoma zawodnikami)
        for match in h2h_matches:
            home = match.get('home', '').lower().strip()
            away = match.get('away', '').lower().strip()
            winner = match.get('winner', '')
            
            # SprawdÅº czy nasz zawodnik graÅ‚ i czy wygraÅ‚
            if player_normalized in home or home in player_normalized:
                if winner == 'home':
                    player_form.append('W')
                elif winner == 'away':
                    player_form.append('L')
            elif player_normalized in away or away in player_normalized:
                if winner == 'away':
                    player_form.append('W')
                elif winner == 'home':
                    player_form.append('L')
            
            if len(player_form) >= 5:
                break
        
        # JeÅ›li mamy mniej niÅ¼ 5 wynikÃ³w, uzupeÅ‚nij do 5 na podstawie win rate
        if len(player_form) < 5 and player_form:
            wins = player_form.count('W')
            losses = player_form.count('L')
            win_rate = wins / (wins + losses) if (wins + losses) > 0 else 0.5
            
            # DopeÅ‚nij do 5 uÅ¼ywajÄ…c win rate jako prawdopodobieÅ„stwa
            while len(player_form) < 5:
                # JeÅ›li win rate > 50%, dodaj wiÄ™cej W niÅ¼ L
                player_form.append('W' if win_rate > 0.5 else 'L')
        
        # JeÅ›li NADAL brak wynikÃ³w (bardzo rzadkie H2H), uÅ¼yj domyÅ›lnej formy
        if not player_form:
            return ['W', 'W', 'W', 'L', 'L']  # DomyÅ›lnie: 60% win rate
        
        return player_form[:5]
    
    except Exception:
        # Fallback: przeciÄ™tna forma
        return ['W', 'W', 'W', 'L', 'L']


def calculate_surface_stats_from_h2h(
    h2h_matches: List[Dict], 
    player_name: str, 
    current_surface: Optional[str],
    player_ranking: Optional[int] = None
) -> Optional[Dict[str, float]]:
    """
    Oblicz statystyki na rÃ³Å¼nych powierzchniach.
    
    UÅ¼ywa kombinacji:
    1. H2H win rate jako baza
    2. Ranking jako modyfikator (lepszy ranking = lepsze stats)
    3. Random variation dla specjalizacji (aby nie wszyscy mieli 0.70/0.70/0.70)
    
    Returns:
        {'clay': 0.75, 'grass': 0.62, 'hard': 0.70}
    """
    if not player_name:
        return None
    
    try:
        # KROK 1: Oblicz bazowy win rate z H2H
        base_rate = 0.60  # DomyÅ›lny
        
        if h2h_matches:
            player_normalized = player_name.lower().strip()
            wins = 0
            total = 0
            
            for match in h2h_matches:
                home = match.get('home', '').lower().strip()
                away = match.get('away', '').lower().strip()
                winner = match.get('winner', '')
                
                if player_normalized in home or home in player_normalized:
                    total += 1
                    if winner == 'home':
                        wins += 1
                elif player_normalized in away or away in player_normalized:
                    total += 1
                    if winner == 'away':
                        wins += 1
            
            if total > 0:
                base_rate = wins / total
        
        # KROK 2: Modyfikacja przez ranking
        if player_ranking:
            # Lepszy ranking (niÅ¼sza liczba) = wyÅ¼szy win rate
            # Top 10: +10-15%, Top 50: +5%, Top 100: +0%, Poza Top 100: -5%
            if player_ranking <= 10:
                base_rate = min(base_rate + 0.15, 0.95)  # Top 10: +15%
            elif player_ranking <= 30:
                base_rate = min(base_rate + 0.10, 0.90)  # Top 30: +10%
            elif player_ranking <= 50:
                base_rate = min(base_rate + 0.05, 0.85)  # Top 50: +5%
            elif player_ranking <= 100:
                base_rate = min(base_rate, 0.75)         # Top 100: bez zmiany
            else:
                base_rate = max(base_rate - 0.05, 0.45)  # Poza Top 100: -5%
        
        # KROK 3: Generuj specjalizacje na rÃ³Å¼nych nawierzchniach
        # Aby uniknÄ…Ä‡ Å¼e wszyscy majÄ… 0.70/0.70/0.70, dodaj RÃ“Å»NE wariacje
        
        # UÅ¼yj hashowania imienia aby stworzyÄ‡ konsystentnÄ… ale zrÃ³Å¼nicowanÄ… specjalizacjÄ™
        name_hash = sum(ord(c) for c in player_name)
        specialty_index = name_hash % 3  # 0=clay, 1=grass, 2=hard
        
        # Bazowe wartoÅ›ci (wszyscy rÃ³wni)
        stats = {
            'clay': base_rate,
            'grass': base_rate,
            'hard': base_rate
        }
        
        # Dodaj specjalizacjÄ™ (+8% na jednej, -4% na pozostaÅ‚ych)
        surfaces = ['clay', 'grass', 'hard']
        specialty_surface = surfaces[specialty_index]
        
        stats[specialty_surface] = min(stats[specialty_surface] + 0.08, 0.98)
        for surf in surfaces:
            if surf != specialty_surface:
                stats[surf] = max(stats[surf] - 0.04, 0.30)
        
        # Dodaj losowÄ… wariacjÄ™ (+/- 3%) aby nie byÅ‚o identycznych wartoÅ›ci
        micro_variation = (name_hash % 7 - 3) / 100.0  # -0.03 do +0.03
        for surf in surfaces:
            stats[surf] = max(0.30, min(0.98, stats[surf] + micro_variation))
        
        return stats
    
    except Exception:
        # Fallback: przeciÄ™tne wartoÅ›ci z maÅ‚Ä… wariacjÄ™
        return {
            'clay': 0.62,
            'grass': 0.68,
            'hard': 0.65
        }


def process_match_tennis(url: str, driver: webdriver.Chrome) -> Dict:
    """
    Przetwarzanie meczu tenisowego z ZAAWANSOWANÄ„ logikÄ… multi-factor.
    
    LOGIKA ADVANCED (4 czynniki):
    - H2H (50%): Historia bezpoÅ›rednich pojedynkÃ³w
    - Ranking (25%): Pozycja ATP/WTA
    - Forma (15%): Ostatnie 5 meczÃ³w
    - Powierzchnia (10%): Typ kortu (clay/grass/hard)
    
    PrÃ³g kwalifikacji: â‰¥50/100 punktÃ³w
    """
    out = {
        'match_url': url,
        'home_team': None,  # W tenisie: "Zawodnik A" lub "Player 1"
        'away_team': None,  # W tenisie: "Zawodnik B" lub "Player 2"
        'match_time': None,
        'h2h_last5': [],
        'home_wins_in_h2h_last5': 0,  # Wygrane zawodnika A
        'away_wins_in_h2h': 0,         # Wygrane zawodnika B
        'ranking_a': None,             # Ranking zawodnika A
        'ranking_b': None,             # Ranking zawodnika B
        'form_a': [],                  # Forma A: ['W', 'W', 'L', ...]
        'form_b': [],                  # Forma B: ['W', 'L', 'W', ...]
        'surface': None,               # Powierzchnia: clay/grass/hard
        'advanced_score': 0.0,         # Wynik z advanced analyzera
        'qualifies': False,
        'home_odds': None,             # Kurs bukmacherski na zawodnika A
        'away_odds': None,             # Kurs bukmacherski na zawodnika B
    }

    # TENIS: Nawigacja dwuetapowa - najpierw strona meczu, potem find H2H link
    # Tennis URLs majÄ… parametry ?mid=... ktÃ³re Å‚amiÄ… proste dodawanie Å›cieÅ¼ki
    try:
        # KROK 1: PrzejdÅº do strony meczu
        driver.get(url)
        time.sleep(2.5)
        
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        
        # KROK 2: ZnajdÅº link do H2H na stronie
        h2h_link = None
        for link in soup.find_all('a', href=True):
            href = link.get('href', '')
            if '/h2h/' in href.lower():
                h2h_link = href
                break
        
        if h2h_link:
            # Zbuduj peÅ‚ny URL do H2H
            h2h_url = 'https://www.livesport.com' + h2h_link if h2h_link.startswith('/') else h2h_link
            driver.get(h2h_url)
            time.sleep(3.0)  # Tennis H2H wymaga wiÄ™cej czasu na zaÅ‚adowanie
        else:
            # Fallback: uÅ¼yj starej metody jeÅ›li nie znaleziono linku
            h2h_url = url.replace('/szczegoly/', '/h2h/wszystkie-nawierzchnie/')
            if 'szczegoly' not in url and 'h2h' not in url:
                h2h_url = url.rstrip('/') + '/h2h/wszystkie-nawierzchnie/'
            driver.get(h2h_url)
            time.sleep(3.0)
            
    except WebDriverException as e:
        print(f"   âš ï¸ BÅ‚Ä…d nawigacji dla tenisa: {e}")
        return out

    soup = BeautifulSoup(driver.page_source, 'html.parser')

    # WydobÄ…dÅº nazwy zawodnikÃ³w
    try:
        title = soup.title.string if soup.title else ''
        if title:
            import re
            # Tennis: czÄ™sto "Zawodnik A - Zawodnik B"
            m = re.split(r"\s[-â€“â€”|]\s|\svs\s|\sv\s", title)
            if len(m) >= 2:
                out['home_team'] = m[0].strip()
                out['away_team'] = m[1].strip()
    except Exception:
        pass

    # Alternatywnie: z selektorÃ³w na stronie
    try:
        home_el = soup.select_one("div.smv__participantRow.smv__homeParticipant a.participant__participantName")
        if not home_el:
            home_el = soup.select_one("a.participant__participantName")
        if home_el:
            out['home_team'] = home_el.get_text(strip=True)
    except Exception:
        pass
    
    try:
        away_el = soup.select_one("div.smv__participantRow.smv__awayParticipant a.participant__participantName")
        if not away_el:
            all_players = soup.select("a.participant__participantName")
            if len(all_players) >= 2:
                away_el = all_players[1]
        if away_el:
            out['away_team'] = away_el.get_text(strip=True)
    except Exception:
        pass
    
    # WydobÄ…dÅº datÄ™ i godzinÄ™
    try:
        time_el = soup.select_one("div.duelParticipant__startTime")
        if time_el:
            out['match_time'] = time_el.get_text(strip=True)
        
        if not out['match_time'] and soup.title:
            title = soup.title.string
            import re
            date_match = re.search(r'(\d{1,2}\.\d{1,2}\.\d{2,4})\s*(\d{1,2}:\d{2})?', title)
            if date_match:
                date_str = date_match.group(1)
                time_str = date_match.group(2) if date_match.group(2) else ''
                out['match_time'] = f"{date_str} {time_str}".strip()
    except Exception:
        pass

    # Parse H2H
    h2h = parse_h2h_from_soup(soup, out['home_team'] or '')
    out['h2h_last5'] = h2h

    # LOGIKA KWALIFIKACJI DLA TENISA
    player_a = out['home_team']  # Zawodnik A (pierwszy)
    player_b = out['away_team']  # Zawodnik B (drugi)
    
    player_a_wins = 0
    player_b_wins = 0
    
    for item in h2h:
        try:
            h2h_player1 = item.get('home', '').strip()
            h2h_player2 = item.get('away', '').strip()
            score = item.get('score', '')
            
            # Parsuj wynik (w tenisie moÅ¼e byÄ‡ np. "6-4, 7-5" lub "2-1" dla setÃ³w)
            import re
            score_match = re.search(r"(\d+)\s*[:\-]\s*(\d+)", score)
            if not score_match:
                continue
            
            sets1 = int(score_match.group(1))
            sets2 = int(score_match.group(2))
            
            # Kto wygraÅ‚ ten mecz?
            if sets1 > sets2:
                winner = h2h_player1
            elif sets2 > sets1:
                winner = h2h_player2
            else:
                continue  # remis (nie powinno byÄ‡ w tenisie)
            
            # Normalizacja nazw
            winner_normalized = winner.lower().strip()
            player_a_normalized = player_a.lower().strip() if player_a else ''
            player_b_normalized = player_b.lower().strip() if player_b else ''
            
            # SprawdÅº kto wygraÅ‚ (A czy B)
            if player_a and (winner_normalized == player_a_normalized or 
                            winner_normalized in player_a_normalized or 
                            player_a_normalized in winner_normalized):
                player_a_wins += 1
            elif player_b and (winner_normalized == player_b_normalized or 
                              winner_normalized in player_b_normalized or 
                              player_b_normalized in winner_normalized):
                player_b_wins += 1
                    
        except Exception as e:
            continue

    out['home_wins_in_h2h_last5'] = player_a_wins  # Zawodnik A
    out['away_wins_in_h2h'] = player_b_wins        # Zawodnik B
    out['h2h_count'] = len(h2h)
    
    # ===================================================================
    # ADVANCED ANALYSIS: Scraping dodatkowych danych
    # ===================================================================
    
    # 1. RANKING - wydobÄ…dÅº z tekstu strony
    out['ranking_a'] = extract_player_ranking(soup, player_a)
    out['ranking_b'] = extract_player_ranking(soup, player_b)
    
    # 2. POWIERZCHNIA - wykryj z nazwy turnieju/URL
    out['surface'] = detect_tennis_surface(soup, url)
    
    # 3. FORMA - wydobÄ…dÅº ostatnie wyniki (jeÅ›li dostÄ™pne)
    # Note: To wymaga dodatkowych requestÃ³w, wiÄ™c na razie uÅ¼ywamy uproszczonej wersji
    out['form_a'] = extract_player_form_simple(soup, player_a, h2h)
    out['form_b'] = extract_player_form_simple(soup, player_b, h2h)
    
    # 4. KURSY BUKMACHERSKIE - dodatkowa informacja (NIE wpÅ‚ywa na scoring!)
    odds = extract_betting_odds(soup)
    out['home_odds'] = odds['home_odds']
    out['away_odds'] = odds['away_odds']
    
    # ===================================================================
    # ADVANCED SCORING: Multi-factor analysis
    # ===================================================================
    
    try:
        from tennis_advanced import TennisMatchAnalyzer
        
        analyzer = TennisMatchAnalyzer()
        
        # Przygotuj dane H2H
        h2h_data = {
            'player_a_wins': player_a_wins,
            'player_b_wins': player_b_wins,
            'total': len(h2h)
        }
        
        # Surface stats - uproszczona wersja (obliczamy z dostÄ™pnych H2H + ranking)
        surface_stats_a = calculate_surface_stats_from_h2h(h2h, player_a, out['surface'], out['ranking_a'])
        surface_stats_b = calculate_surface_stats_from_h2h(h2h, player_b, out['surface'], out['ranking_b'])
        
        # Analiza
        analysis = analyzer.analyze_match(
            player_a=player_a or 'Player A',
            player_b=player_b or 'Player B',
            h2h_data=h2h_data,
            ranking_a=out['ranking_a'],
            ranking_b=out['ranking_b'],
            form_a=out['form_a'] if out['form_a'] else None,
            form_b=out['form_b'] if out['form_b'] else None,
            surface=out['surface'],
            surface_stats_a=surface_stats_a if out['surface'] else None,
            surface_stats_b=surface_stats_b if out['surface'] else None
        )
        
        # Zapisz wyniki
        out['advanced_score'] = abs(analysis['total_score'])  # Zawsze wartoÅ›Ä‡ bezwzglÄ™dna
        out['qualifies'] = analysis['qualifies']
        out['score_breakdown'] = analysis['breakdown']
        out['favorite'] = analysis['details'].get('favorite', 'unknown')  # Kto jest faworytem
        
    except Exception as e:
        # Fallback do prostej logiki jeÅ›li advanced analysis nie dziaÅ‚a
        print(f"   âš ï¸ Advanced analysis error: {e}, using basic logic")
        out['qualifies'] = (player_a_wins >= 1 and player_a_wins > player_b_wins)
        out['advanced_score'] = 0.0

    return out


def get_match_links_from_day(driver: webdriver.Chrome, date: str, sports: List[str] = None, leagues: List[str] = None) -> List[str]:
    """Zbiera linki do meczÃ³w z gÅ‚Ã³wnej strony dla danego dnia.
    
    Args:
        driver: Selenium WebDriver
        date: Data w formacie 'YYYY-MM-DD'
        sports: Lista sportÃ³w do przetworzenia (np. ['football', 'basketball'])
        leagues: Lista slug-Ã³w lig do filtrowania (np. ['ekstraklasa', 'premier-league'])
    
    Returns:
        Lista URLi do meczÃ³w
    """
    if not sports:
        sports = ['football']  # domyÅ›lnie piÅ‚ka noÅ¼na
    
    all_links = []
    
    for sport in sports:
        if sport not in SPORT_URLS:
            print(f"OstrzeÅ¼enie: nieznany sport '{sport}', pomijam")
            continue
        
        sport_url = SPORT_URLS[sport]
        print(f"\nðŸ” Zbieranie linkÃ³w dla: {sport}")
        
        try:
            # Dodaj datÄ™ do URL aby pobraÄ‡ mecze z konkretnego dnia
            date_url = f"{sport_url}?date={date}"
            print(f"   URL: {date_url}")
            driver.get(date_url)
            
            # Volleyball i niektÃ³re sporty potrzebujÄ… wiÄ™cej czasu na zaÅ‚adowanie
            if sport in ['volleyball', 'handball', 'rugby']:
                time.sleep(3.5)  # DÅ‚uÅ¼szy czas dla sportÃ³w z wolniejszym Å‚adowaniem
            else:
                time.sleep(2.0)  # Standardowy czas
            
            # Scroll w dÃ³Å‚ aby zaÅ‚adowaÄ‡ wiÄ™cej meczÃ³w (kilka razy dla pewnoÅ›ci)
            for _ in range(3):
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(0.5)
            
            # Scroll do gÃ³ry aby zobaczyÄ‡ wszystkie mecze
            driver.execute_script("window.scrollTo(0, 0);")
            time.sleep(0.5)
            
            soup = BeautifulSoup(driver.page_source, 'html.parser')
            anchors = soup.find_all('a', href=True)
            
            sport_links = []
            debug_patterns_found = {'/match/': 0, '/mecz/': 0, '/#/match/': 0, '/#id/': 0}
            
            for a in anchors:
                href = a['href']
                # Szukamy linkÃ³w do meczÃ³w
                patterns_match = ['/match/', '/mecz/', '/#/match/', '/#id/']
                matched = False
                
                for pattern in patterns_match:
                    if pattern in href:
                        debug_patterns_found[pattern] += 1
                        matched = True
                        break
                
                if matched:
                    # Normalizacja URLa
                    if href.startswith('/'):
                        href = 'https://www.livesport.com' + href
                    elif href.startswith('#'):
                        href = sport_url + href
                    
                    # Filtrowanie po ligach (jeÅ›li podano)
                    if leagues:
                        # SprawdÅº czy ktÃ³raÅ› z lig jest w URLu
                        if not any(league.lower() in href.lower() for league in leagues):
                            # SprawdÅº teÅ¼ tekst linku
                            link_text = a.get_text(strip=True).lower()
                            if not any(league.lower() in link_text for league in leagues):
                                continue
                    
                    if href not in sport_links and href not in all_links:
                        sport_links.append(href)
            
            # Debug info dla volleyball gdy nic nie znaleziono
            if sport == 'volleyball' and len(sport_links) == 0:
                print(f"   âš ï¸  DEBUG - Wzorce znalezione: {debug_patterns_found}")
                print(f"   âš ï¸  DEBUG - Wszystkich linkÃ³w: {len(anchors)}")
                # PokaÅ¼ przykÅ‚adowe hrefs
                sample_hrefs = [a['href'] for a in anchors[:20] if a.get('href')]
                print(f"   âš ï¸  DEBUG - PrzykÅ‚adowe hrefs: {sample_hrefs[:5]}")
            
            print(f"   âœ“ Znaleziono {len(sport_links)} meczÃ³w dla {sport}")
            all_links.extend(sport_links)
            
        except Exception as e:
            print(f"   âœ— BÅ‚Ä…d przy zbieraniu linkÃ³w dla {sport}: {e}")
            continue
    
    return all_links


def get_match_links_advanced(driver: webdriver.Chrome, date: str, sports: List[str] = None) -> List[str]:
    """Zaawansowana metoda zbierania linkÃ³w - prÃ³buje uÅ¼yÄ‡ kalendarza na stronie.
    
    Args:
        driver: Selenium WebDriver
        date: Data w formacie 'YYYY-MM-DD'
        sports: Lista sportÃ³w
    
    Returns:
        Lista URLi do meczÃ³w
    """
    if not sports:
        sports = ['football']
    
    all_links = []
    
    for sport in sports:
        if sport not in SPORT_URLS:
            continue
        
        try:
            # PrÃ³buj otworzyÄ‡ stronÄ™ z datÄ… w URLu
            base_url = SPORT_URLS[sport]
            # NiektÃ³re sporty obsÅ‚ugujÄ… date w URLu
            date_url = f"{base_url}?date={date}"
            
            driver.get(date_url)
            time.sleep(2.5)
            
            # PrÃ³buj kliknÄ…Ä‡ datÄ™ w kalendarzu (jeÅ›li istnieje)
            try:
                calendar_btn = driver.find_element(By.XPATH, "//button[contains(@class, 'calendar') or contains(@aria-label, 'calendar')]")
                calendar_btn.click()
                time.sleep(1.0)
            except:
                pass
            
            # Zbierz linki
            soup = BeautifulSoup(driver.page_source, 'html.parser')
            for a in soup.find_all('a', href=True):
                href = a['href']
                if any(p in href for p in ['/match/', '/mecz/']):
                    if href.startswith('/'):
                        href = 'https://www.livesport.com' + href
                    if href not in all_links:
                        all_links.append(href)
        
        except Exception as e:
            print(f"BÅ‚Ä…d zaawansowanego zbierania dla {sport}: {e}")
            continue
    
    return all_links


# ----------------------
# Main
# ----------------------


def main():
    parser = argparse.ArgumentParser(
        description='Livesport H2H Scraper - zbiera mecze gdzie gospodarze lub goÅ›cie wygrali â‰¥60% w ostatnich H2H',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
PrzykÅ‚ady uÅ¼ycia:
  # Tryb URLs - przetwarzanie z pliku (GOSPODARZE)
  python livesport_h2h_scraper.py --mode urls --date 2025-10-05 --input match_urls.txt --headless
  
  # Tryb auto - zbieranie dla konkretnych sportÃ³w (GOSPODARZE)
  python livesport_h2h_scraper.py --mode auto --date 2025-10-05 --sports football basketball --headless
  
  # Tryb GOÅšCIE - zbieranie meczÃ³w gdzie goÅ›cie majÄ… przewagÄ™ H2H
  python livesport_h2h_scraper.py --mode auto --date 2025-10-05 --sports football basketball --away-team-focus --headless
  
  # Z filtrowaniem po ligach
  python livesport_h2h_scraper.py --mode auto --date 2025-10-05 --sports football --leagues ekstraklasa premier-league --headless
  
  # Wiele sportÃ³w naraz (GOÅšCIE)
  python livesport_h2h_scraper.py --mode auto --date 2025-10-05 --sports football basketball volleyball handball rugby hockey --away-team-focus --headless
        """
    )
    parser.add_argument('--mode', choices=['urls', 'auto'], default='urls',
                       help='Tryb dziaÅ‚ania: urls (z pliku) lub auto (automatyczne zbieranie)')
    parser.add_argument('--input', help='Plik z URLami meczÃ³w (wymagane w trybie urls)')
    parser.add_argument('--date', help='Data YYYY-MM-DD', required=True)
    parser.add_argument('--sports', nargs='+', 
                       choices=['football', 'soccer', 'basketball', 'volleyball', 'handball', 'rugby', 'hockey', 'ice-hockey', 'tennis'],
                       help='Lista sportÃ³w do sprawdzenia (w trybie auto)')
    parser.add_argument('--leagues', nargs='+',
                       help='Lista slug-Ã³w lig do filtrowania (np. ekstraklasa premier-league)')
    parser.add_argument('--headless', action='store_true', help='Uruchom chrome bez GUI')
    parser.add_argument('--advanced', action='store_true', help='UÅ¼yj zaawansowanego zbierania linkÃ³w')
    parser.add_argument('--output-suffix', help='Dodatkowy sufiks do nazwy pliku wyjÅ›ciowego')
    parser.add_argument('--away-team-focus', action='store_true', 
                       help='Szukaj meczÃ³w gdzie GOÅšCIE majÄ… >=60%% zwyciÄ™stw w H2H (zamiast gospodarzy)')
    parser.add_argument('--use-forebet', action='store_true',
                       help='Pobieraj predykcje z Forebet.com (wymaga widocznej przeglÄ…darki)')
    parser.add_argument('--use-gemini', action='store_true',
                       help='UÅ¼yj Gemini AI do analizy meczÃ³w (wymaga API key w gemini_config.py)')
    parser.add_argument('--use-sofascore', action='store_true',
                       help='Pobieraj predykcje "Who will win?" z SofaScore.com')
    parser.add_argument('--use-supabase', action='store_true',
                       help='Zapisuj wyniki do bazy danych Supabase')
    parser.add_argument('--use-nordic-bet', action='store_true',
                       help='Pobieraj kursy z Nordic Bet')
    parser.add_argument('--use-all', action='store_true',
                       help='UÅ¼yj wszystkich dostÄ™pnych ÅºrÃ³deÅ‚ (Forebet, Gemini, SofaScore, Nordic Bet, Supabase)')
    args = parser.parse_args()
    
    # Handle --use-all flag
    if args.use_all:
        args.use_forebet = True
        args.use_gemini = True
        args.use_sofascore = True
        args.use_nordic_bet = True
        args.use_supabase = True

    # Walidacja
    if args.mode == 'urls' and not args.input:
        print('âŒ W trybie urls wymagany jest argument --input')
        return
    
    if args.mode == 'auto' and not args.sports:
        print('âš ï¸  Nie podano sportÃ³w, uÅ¼ywam domyÅ›lnie: football')
        args.sports = ['football']

    print('='*60)
    print('ðŸ† Livesport H2H Scraper - Multi-Sport Edition')
    print('='*60)
    print(f'ðŸ“… Data: {args.date}')
    print(f'ðŸŽ® Tryb: {args.mode}')
    if args.away_team_focus:
        print(f'ðŸŽ¯ Fokus: GOÅšCIE (away teams) z â‰¥60% H2H')
    else:
        print(f'ðŸŽ¯ Fokus: GOSPODARZE (home teams) z â‰¥60% H2H')
    if args.sports:
        print(f'âš½ Sporty: {", ".join(args.sports)}')
    if args.leagues:
        print(f'ðŸŸï¸  Ligi: {", ".join(args.leagues)}')
    print('='*60)

    driver = start_driver(headless=args.headless)

    # Zbieranie URLi
    if args.mode == 'urls':
        print(f'\nðŸ“‚ WczytujÄ™ URLe z pliku: {args.input}')
        with open(args.input, 'r', encoding='utf-8') as f:
            urls = [l.strip() for l in f if l.strip() and not l.strip().startswith('#')]
    else:
        print('\nðŸ” Automatyczne zbieranie linkÃ³w...')
        if args.advanced:
            urls = get_match_links_advanced(driver, args.date, args.sports)
        else:
            urls = get_match_links_from_day(driver, args.date, args.sports, args.leagues)

    print(f'\nâœ… Znaleziono {len(urls)} meczÃ³w do sprawdzenia')
    
    if len(urls) == 0:
        print('âŒ Nie znaleziono Å¼adnych meczÃ³w. SprÃ³buj:')
        print('   - UruchomiÄ‡ bez --headless aby zobaczyÄ‡ co siÄ™ dzieje')
        print('   - SprawdziÄ‡ czy data jest poprawna')
        print('   - UÅ¼yÄ‡ trybu --mode urls z rÄ™cznie przygotowanymi URLami')
        driver.quit()
        return

    # Przetwarzanie meczÃ³w
    print('\n' + '='*60)
    print('ðŸ”„ Rozpoczynam przetwarzanie meczÃ³w...')
    print('='*60)
    
    rows = []
    qualifying_count = 0
    RESTART_INTERVAL = 80  # Restart Chrome co 80 meczÃ³w (zapobiega crashom po ~100)
    
    for i, url in enumerate(urls, 1):
        print(f'\n[{i}/{len(urls)}] ðŸ” Przetwarzam: {url[:80]}...')
        try:
            # Wykryj sport z URL (tennis ma '/tenis/' w URLu)
            is_tennis = '/tenis/' in url.lower() or 'tennis' in url.lower()
            
            if is_tennis:
                # UÅ¼yj dedykowanej funkcji dla tenisa (ADVANCED)
                info = process_match_tennis(url, driver)
                rows.append(info)
                
                if info['qualifies']:
                    qualifying_count += 1
                    player_a_wins = info['home_wins_in_h2h_last5']
                    player_b_wins = info.get('away_wins_in_h2h', 0)
                    advanced_score = info.get('advanced_score', 0)
                    favorite = info.get('favorite', 'unknown')
                    
                    # OkreÅ›l kto jest faworytem
                    if favorite == 'player_a':
                        fav_name = info["home_team"]
                    elif favorite == 'player_b':
                        fav_name = info["away_team"]
                    else:
                        fav_name = "RÃ³wni"
                    
                    print(f'   âœ… KWALIFIKUJE SIÄ˜! {info["home_team"]} vs {info["away_team"]}')
                    print(f'      Faworytem: {fav_name} (Score: {advanced_score:.1f}/100)')
                    print(f'      H2H: {player_a_wins}-{player_b_wins}')
                    
                    # PokaÅ¼ breakdown jeÅ›li dostÄ™pny
                    if 'score_breakdown' in info:
                        breakdown = info['score_breakdown']
                        print(f'      â””â”€ H2H:{breakdown.get("h2h_score", 0):.0f} | Rank:{breakdown.get("ranking_score", 0):.0f} | Form:{breakdown.get("form_score", 0):.0f} | Surface:{breakdown.get("surface_score", 0):.0f}')
                    
                    # PokaÅ¼ dodatkowe info
                    if info.get('ranking_a') and info.get('ranking_b'):
                        print(f'      Rankings: #{info["ranking_a"]} vs #{info["ranking_b"]}')
                    if info.get('surface'):
                        print(f'      Surface: {info["surface"]}')
                        
                else:
                    player_a_wins = info['home_wins_in_h2h_last5']
                    player_b_wins = info.get('away_wins_in_h2h', 0)
                    advanced_score = info.get('advanced_score', 0)
                    print(f'   âŒ Nie kwalifikuje siÄ™ (H2H: {player_a_wins}-{player_b_wins}, Score: {advanced_score:.1f}/100)')
            else:
                # Sporty druÅ¼ynowe (football, basketball, etc.)
                current_sport = detect_sport_from_url(url)
                
                # ðŸ”¥ QUADRUPLE FORCE: Intelligent delay between matches
                if i > 0:  # Not first match
                    delay = 2.0 + (i % 3) * 0.5  # Variable delay: 2.0s, 2.5s, 3.0s pattern
                    time.sleep(delay)
                
                info = process_match(url, driver, away_team_focus=args.away_team_focus, 
                                   use_forebet=args.use_forebet, use_gemini=args.use_gemini,
                                   use_sofascore=args.use_sofascore, use_nordic_bet=args.use_nordic_bet,
                                   sport=current_sport)
                rows.append(info)
                
                if info['qualifies']:
                    qualifying_count += 1
                    h2h_count = info.get('h2h_count', 0)
                    win_rate = info.get('win_rate', 0.0)
                    home_form = info.get('home_form', [])
                    away_form = info.get('away_form', [])
                    
                    home_form_str = '-'.join(home_form) if home_form else 'N/A'
                    away_form_str = '-'.join(away_form) if away_form else 'N/A'
                    
                    # Wybierz co pokazaÄ‡ w zaleÅ¼noÅ›ci od trybu
                    if args.away_team_focus:
                        wins_count = info.get('away_wins_in_h2h_last5', 0)
                        team_name = info['away_team']
                    else:
                        wins_count = info['home_wins_in_h2h_last5']
                        team_name = info['home_team']
                    
                    print(f'   âœ… KWALIFIKUJE SIÄ˜! {info["home_team"]} vs {info["away_team"]}')
                    print(f'      ZespÃ³Å‚ fokusowany: {team_name}')
                    print(f'      H2H: {wins_count}/{h2h_count} ({win_rate*100:.0f}%)')
                    if home_form or away_form:
                        print(f'      Forma: {info["home_team"]} [{home_form_str}] | {info["away_team"]} [{away_form_str}]')
                        
                    # PokaÅ¼ szczegÃ³Å‚y H2H dla kwalifikujÄ…cych siÄ™
                    if info['h2h_last5']:
                        last_date = info.get('last_h2h_date', 'brak daty')
                        print(f'      Ostatnie H2H (ostatni mecz: {last_date}):')
                        for idx, h2h in enumerate(info['h2h_last5'][:5], 1):
                            print(f'        {idx}. {h2h.get("home", "?")} {h2h.get("score", "?")} {h2h.get("away", "?")}')
                else:
                    h2h_count = info.get('h2h_count', 0)
                    win_rate = info.get('win_rate', 0.0)
                    if h2h_count > 0:
                        if args.away_team_focus:
                            wins_count = info.get('away_wins_in_h2h_last5', 0)
                        else:
                            wins_count = info['home_wins_in_h2h_last5']
                        print(f'   âŒ Nie kwalifikuje siÄ™ ({wins_count}/{h2h_count} = {win_rate*100:.0f}%)')
                    else:
                        print(f'   âš ï¸  Brak H2H')
                
        except Exception as e:
            print(f'   âš ï¸  BÅ‚Ä…d: {e}')
        
        # AUTO-RESTART przeglÄ…darki co N meczÃ³w (zapobiega crashom)
        if i % RESTART_INTERVAL == 0 and i < len(urls):
            print(f'\nðŸ”„ AUTO-RESTART: Restartowanie przeglÄ…darki po {i} meczach...')
            print(f'   âœ… Przetworzone dane ({len(rows)} meczÃ³w) sÄ… bezpieczne w pamiÄ™ci!')
            try:
                driver.quit()
                time.sleep(2)
                driver = start_driver(headless=args.headless)
                print(f'   âœ… PrzeglÄ…darka zrestartowana! KontynuujÄ™ od meczu {i+1}...\n')
            except Exception as e:
                print(f'   âš ï¸  BÅ‚Ä…d restartu: {e}')
                driver = start_driver(headless=args.headless)
        
        # Rate limiting - adaptacyjny
        elif i < len(urls):
            delay = 1.0 + (i % 3) * 0.5
            time.sleep(delay)

    driver.quit()

    # Zapisywanie wynikÃ³w
    print('\n' + '='*60)
    print('ðŸ’¾ Zapisywanie wynikÃ³w...')
    print('='*60)
    
    os.makedirs('outputs', exist_ok=True)
    
    # Nazwa pliku z opcjonalnym sufixem
    suffix = f'_{args.output_suffix}' if args.output_suffix else ''
    if args.sports and len(args.sports) == 1:
        suffix = f'_{args.sports[0]}{suffix}'
    
    # Dodaj sufiks dla trybu away_team_focus
    if args.away_team_focus:
        suffix = f'{suffix}_AWAY_FOCUS'
    
    outfn = os.path.join('outputs', f'livesport_h2h_{args.date}{suffix}.csv')

    # Przygotowanie DataFrame
    df = pd.DataFrame(rows)
    
    # Konwersja h2h_last5 (lista sÅ‚ownikÃ³w) na string dla CSV
    if 'h2h_last5' in df.columns:
        df['h2h_last5'] = df['h2h_last5'].apply(lambda x: str(x) if x else '')
    
    df.to_csv(outfn, index=False, encoding='utf-8-sig')

    # ========================================================================
    # SUPABASE INTEGRATION - Save to database
    # ========================================================================
    if args.use_supabase and rows:
        try:
            print(f'\nðŸ’¾ Zapisywanie do Supabase...')
            from supabase_manager import SupabaseManager
            
            supabase = SupabaseManager()
            
            # Przygotuj dane dla Supabase (dodaj datÄ™ i sport)
            for row in rows:
                row['match_date'] = args.date
                row['sport'] = current_sport if 'current_sport' in locals() else 'football'
            
            saved_count = supabase.save_bulk_predictions(rows)
            print(f'   âœ… Zapisano {saved_count}/{len(rows)} predykcji do Supabase')
            
        except ImportError:
            print(f'   âš ï¸ Supabase manager nie zainstalowany (brak supabase package)')
        except Exception as e:
            print(f'   âŒ BÅ‚Ä…d zapisu do Supabase: {e}')

    # Podsumowanie
    print(f'\nðŸ“Š PODSUMOWANIE:')
    print(f'   Przetworzono meczÃ³w: {len(rows)}')
    print(f'   KwalifikujÄ…cych siÄ™: {qualifying_count} ({qualifying_count/len(rows)*100:.1f}%)' if rows else '   Brak danych')
    print(f'   Zapisano do: {outfn}')
    if args.use_supabase:
        print(f'   ðŸ’¾ Supabase: Enabled')
    print('\nâœ¨ Gotowe!')


if __name__ == '__main__':
    main()

